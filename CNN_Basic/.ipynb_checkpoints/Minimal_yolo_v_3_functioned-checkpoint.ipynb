{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2hDx1_O_absD"
   },
   "source": [
    "### Initialization Bock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5812,
     "status": "ok",
     "timestamp": 1562823131674,
     "user": {
      "displayName": "irfan hasib",
      "photoUrl": "https://lh4.googleusercontent.com/-6rVnRThUoWk/AAAAAAAAAAI/AAAAAAAADsk/X6dBOaUVMS4/s64/photo.jpg",
      "userId": "16061096143782894681"
     },
     "user_tz": -360
    },
    "id": "h1HPqGKtZdQ8",
    "outputId": "0543c1fe-60df-4bca-cf10-212504dd2dab"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3624f8561cee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mReshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvanced_activations\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "colab_run=False\n",
    "anc_box= False\n",
    "train=True\n",
    "if colab_run==True:\n",
    "  !pip install pydrive\n",
    "  from pydrive.auth import GoogleAuth\n",
    "  from pydrive.drive import GoogleDrive\n",
    "  from google.colab import auth\n",
    "  from oauth2client.client import GoogleCredentials\n",
    "\n",
    "  auth.authenticate_user()\n",
    "  gauth = GoogleAuth()\n",
    "  gauth.credentials = GoogleCredentials.get_application_default()\n",
    "  drive = GoogleDrive(gauth)\n",
    "\n",
    "  import os, cv2\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive/')\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.layers.merge import concatenate\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os, cv2\n",
    "\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# %matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XcCwnGYHaul2"
   },
   "source": [
    "### Configure Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5eIxqVja27b"
   },
   "source": [
    "### Model Building Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDHEMWhWZo40"
   },
   "outputs": [],
   "source": [
    "LABELS=['person', 'bird', 'cat', 'cow', 'dog', 'horse', 'sheep','aeroplane', 'bicycle',\n",
    "         'boat', 'bus', 'car', 'motorbike', 'train', 'bottle', 'chair','dining table',\n",
    "         'potted plant', 'sofa', 'tvmonitor']\n",
    "\n",
    "IMAGE_H, IMAGE_W = 416, 416\n",
    "GRID_H,  GRID_W  = 13 , 13\n",
    "BOX              = 5\n",
    "CLASS            = len(LABELS)\n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "OBJ_THRESHOLD    = 0.3#0.5\n",
    "NMS_THRESHOLD    = 0.3#0.45\n",
    "#ANCHORS          = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "ANCHORS          = [ 4.469053,2.148582,10.548851,5.381520,11.420664,9.961033,6.517299,3.699693,2.469196,1.599054]\n",
    "#ANCHORS=[13,13]\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 20\n",
    "WARM_UP_BATCHES  = 0\n",
    "TRUE_BOX_BUFFER  = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJnrCWISZz8S"
   },
   "outputs": [],
   "source": [
    "# the function to implement the orgnization layer (thanks to github.com/allanzelener/YAD2K)\n",
    "def space_to_depth_x2(x):\n",
    "    return tf.space_to_depth(x, block_size=2)\n",
    "\n",
    "def build_model():\n",
    "  input_image = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
    "  true_boxes  = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\n",
    "\n",
    "  # Layer 1\n",
    "  x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "  x = BatchNormalization(name='norm_1')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "  # Layer 2\n",
    "  x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_2')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "  # Layer 3\n",
    "  x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_3')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 4\n",
    "  x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_4')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 5\n",
    "  x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_5')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "  # Layer 6\n",
    "  x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_6')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 7\n",
    "  x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_7')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 8\n",
    "  x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_8')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "  # Layer 9\n",
    "  x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_9')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 10\n",
    "  x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_10')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 11\n",
    "  x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_11')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 12\n",
    "  x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_12')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 13\n",
    "  x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_13')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  skip_connection = x\n",
    "\n",
    "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "  # Layer 14\n",
    "  x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_14')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 15\n",
    "  x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_15')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 16\n",
    "  x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_16')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 17\n",
    "  x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_17')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 18\n",
    "  x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_18')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 19\n",
    "  x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_19')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 20\n",
    "  x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_20')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 21\n",
    "  skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "  skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "  skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "  skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "  x = concatenate([skip_connection, x])\n",
    "\n",
    "  # Layer 22\n",
    "  x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_22')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  if anc_box==True:\n",
    "    # Layer 23\n",
    "    x = Conv2D(BOX*(4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "    output = Reshape((GRID_H, GRID_W,BOX,4 + 1 + CLASS))(x)\n",
    "  else :\n",
    "    # Layer 23\n",
    "    x = Conv2D((4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "    output = Reshape((GRID_H, GRID_W,4 + 1 + CLASS))(x)\n",
    "\n",
    "  # small hack to allow true_boxes to be registered when Keras build the model \n",
    "  # for more information: https://github.com/fchollet/keras/issues/2790\n",
    "  #output = Lambda(lambda args: args[0])([output, true_boxes])#Change :Hasib\n",
    "\n",
    "  #model = Model([input_image, true_boxes], output)#Change :Hasib\n",
    "  model = Model(input_image, output)\n",
    "  return model\n",
    "  #model.load_weights('/content/drive/My Drive/Data/yolo_net_ep500_act.h5')\n",
    "\n",
    "\n",
    "class WeightReader:\n",
    "    def __init__(self, weight_file):\n",
    "        self.offset = 4\n",
    "        self.all_weights = np.fromfile(weight_file, dtype='float32')\n",
    "        \n",
    "    def read_bytes(self, size):\n",
    "        self.offset = self.offset + size\n",
    "        return self.all_weights[self.offset-size:self.offset]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.offset = 4\n",
    "\n",
    "def load_weights(model,path_wst):\n",
    "  wt_path = path_wts                      \n",
    "  weight_reader = WeightReader(wt_path)\n",
    "  weight_reader.reset()\n",
    "  nb_conv = 23\n",
    "\n",
    "  for i in range(1, nb_conv+1):\n",
    "      conv_layer = model.get_layer('conv_' + str(i))\n",
    "\n",
    "      if i < nb_conv:\n",
    "          norm_layer = model.get_layer('norm_' + str(i))\n",
    "\n",
    "          size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\n",
    "          beta  = weight_reader.read_bytes(size)\n",
    "          gamma = weight_reader.read_bytes(size)\n",
    "          mean  = weight_reader.read_bytes(size)\n",
    "          var   = weight_reader.read_bytes(size)\n",
    "\n",
    "          weights = norm_layer.set_weights([gamma, beta, mean, var])       \n",
    "\n",
    "      if len(conv_layer.get_weights()) > 1:\n",
    "          bias   = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "          kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "          kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "          kernel = kernel.transpose([2,3,1,0])\n",
    "          conv_layer.set_weights([kernel, bias])\n",
    "      else:\n",
    "          kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "          kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "          kernel = kernel.transpose([2,3,1,0])\n",
    "          conv_layer.set_weights([kernel])\n",
    "  return model\n",
    "\n",
    "\n",
    "def yolo_loss_0(y_true, y_pred):\n",
    "        loss=0\n",
    "      #for n in range(BATCH_SIZE):\n",
    "        for i in range(GRID_H):\n",
    "          for j in range(GRID_W):\n",
    "            for k in range(0,6):\n",
    "              temp=y_true[i,j,k]-y_pred[i,j,k]\n",
    "              #temp=temp**2\n",
    "              loss+=temp\n",
    "              \n",
    "        return loss \n",
    "def yolo_loss_1(y_true, y_pred):\n",
    "      loss=0\n",
    "          ### adjust w and h\n",
    "      ob_mask= tf.expand_dims(y_true[..., 4], axis=-1)\n",
    "      conf_mask=y_true[...,4]\n",
    "      \n",
    "      if anc_box==True:\n",
    "        cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
    "        cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "        cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\n",
    "\n",
    "        pred_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "        pred_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n",
    "      \n",
    "      else:\n",
    "        pred_xy=(y_pred[...,0:2])\n",
    "        pred_wh=(y_pred[...,2:4])\n",
    "      \n",
    "      true_xy=y_true[...,0:2]\n",
    "      true_wh=y_true[...,2:4]\n",
    "      \n",
    "      #pred_wh=tf.multiply(pred_wh,ob_mask)\n",
    "      pred_conf=y_pred[...,4]\n",
    "      ### adjust confidence\n",
    "      true_wh_half = true_wh / 2.\n",
    "      true_mins    = tf.subtract(true_xy,true_wh_half)\n",
    "      true_maxes   = tf.add(true_xy,true_wh_half)\n",
    "    \n",
    "      pred_wh_half = pred_wh / 2.\n",
    "      pred_mins    = tf.subtract(pred_xy,pred_wh_half)\n",
    "      pred_maxes   = tf.add(pred_xy,pred_wh_half)       \n",
    "    \n",
    "      intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "      intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "      intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "      intersect_areas = tf.multiply(intersect_wh[..., 0] , intersect_wh[..., 1])\n",
    "    \n",
    "      true_areas = tf.multiply(true_wh[..., 0] , true_wh[..., 1])\n",
    "      pred_areas = tf.multiply(pred_wh[..., 0] , pred_wh[..., 1])\n",
    "\n",
    "      union_areas =tf.subtract(tf.add(pred_areas,true_areas),intersect_areas)\n",
    "      intersect_areas=tf.add(intersect_areas,1)\n",
    "      union_areas=tf.add(union_areas,1)\n",
    "      iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "      \n",
    "      true_conf =tf.multiply( iou_scores,y_true[..., 4])\n",
    "      \n",
    "      loss_bb=tf.subtract(true_xy,pred_xy)\n",
    "      loss_bb=tf.square(loss_bb)\n",
    "      loss_bb=tf.multiply(loss_bb,ob_mask)\n",
    "      loss_bb=tf.reduce_sum(loss_bb)\n",
    "      loss_wh=tf.subtract((true_wh),(pred_wh))\n",
    "      loss_wh=tf.square(loss_wh)\n",
    "      loss_wh=tf.multiply(loss_wh,ob_mask)\n",
    "      loss_wh=tf.reduce_sum(loss_wh)\n",
    "      loss_conf=tf.subtract(true_conf,pred_conf)\n",
    "      loss_conf=tf.square(loss_conf)\n",
    "      loss_conf=tf.multiply(loss_conf,conf_mask)\n",
    "      loss_conf=tf.reduce_sum(loss_conf)\n",
    "      loss=loss_bb+loss_wh+loss_conf       \n",
    "      return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNFzCsqgTlHT"
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "    \n",
    "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
    "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "\n",
    "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\n",
    "    \n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    conf_mask  = tf.zeros(mask_shape)\n",
    "    class_mask = tf.zeros(mask_shape)\n",
    "    \n",
    "    seen = tf.Variable(0.)\n",
    "    total_recall = tf.Variable(0.)\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust prediction\n",
    "    \"\"\"\n",
    "    ### adjust x and y      \n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "    \n",
    "    ### adjust w and h\n",
    "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n",
    "    \n",
    "    ### adjust confidence\n",
    "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    pred_box_class = y_pred[..., 5:]\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust ground truth\n",
    "    \"\"\"\n",
    "    ### adjust x and y\n",
    "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
    "    \n",
    "    ### adjust w and h\n",
    "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
    "    \n",
    "    ### adjust confidence\n",
    "    true_wh_half = true_box_wh / 2.\n",
    "    true_mins    = true_box_xy - true_wh_half\n",
    "    true_maxes   = true_box_xy + true_wh_half\n",
    "    \n",
    "    pred_wh_half = pred_box_wh / 2.\n",
    "    pred_mins    = pred_box_xy - pred_wh_half\n",
    "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "    \n",
    "    true_box_conf = iou_scores * y_true[..., 4]\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "    \n",
    "    \"\"\"\n",
    "    Determine the masks\n",
    "    \"\"\"\n",
    "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
    "    \n",
    "    ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
    "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "    '''\n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "    \n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins    = true_xy - true_wh_half\n",
    "    true_maxes   = true_xy + true_wh_half\n",
    "    \n",
    "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "    \n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins    = pred_xy - pred_wh_half\n",
    "    pred_maxes   = pred_xy + pred_wh_half    \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    best_ious = tf.reduce_max(iou_scores, axis=4) \n",
    "    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
    "    '''\n",
    "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\n",
    "    \n",
    "    ### class mask: simply the position of the ground truth boxes (the predictors)\n",
    "    class_mask = y_true[..., 4] * tf.gather(CLASS_WEIGHTS, true_box_class) * CLASS_SCALE       \n",
    "    '''\n",
    "    \"\"\"\n",
    "    Warm-up training\n",
    "    \"\"\"\n",
    "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n",
    "    seen = tf.assign_add(seen, 1.)\n",
    "    \n",
    "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES), \n",
    "                          lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n",
    "                                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2]) * no_boxes_mask, \n",
    "                                   tf.ones_like(coord_mask)],\n",
    "                          lambda: [true_box_xy, \n",
    "                                   true_box_wh,\n",
    "                                   coord_mask])\n",
    "    '''\n",
    "    \"\"\"\n",
    "    Finalize the loss\n",
    "    \"\"\"\n",
    "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
    "    nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
    "    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
    "    \n",
    "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
    "    \n",
    "    loss = loss_xy + loss_wh + loss_conf + loss_class\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9qdIbN_a8at"
   },
   "source": [
    "### Data Ready Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAALW0WuaCuO"
   },
   "outputs": [],
   "source": [
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "             return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3          \n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    box1_xmin,box1_ymin,box1_xmax,box1_ymax=box1\n",
    "    box2_xmin,box2_ymin,box2_xmax,box2_ymax=box2\n",
    "    intersect_w = _interval_overlap([box1_xmin, box1_xmax], [box2_xmin, box2_xmax])\n",
    "    intersect_h = _interval_overlap([box1_ymin, box1_ymax], [box2_ymin, box2_ymax])  \n",
    "    \n",
    "    intersect = intersect_w * intersect_h\n",
    "\n",
    "    w1, h1 = box1_xmax-box1_xmin, box1_ymax-box1_ymin\n",
    "    w2, h2 = box2_xmax-box2_xmin, box2_ymax-box2_ymin\n",
    "    \n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    \n",
    "    return float(intersect) / union\n",
    "  \n",
    "def Batch_Gen(train_imgs):\n",
    "        n=len(train_imgs)\n",
    "        x_batch = np.zeros((n,IMAGE_H, IMAGE_W,3),dtype=float)                         # input images\n",
    "        #b_batch = np.zeros((r_bound - l_bound, 1     , 1     , 1    ,  self.config['TRUE_BOX_BUFFER'], 4))   # list of self.config['TRUE_self.config['BOX']_BUFFER'] GT boxes\n",
    "        if anc_box==True:\n",
    "          y_batch = np.zeros((n, GRID_H, GRID_W,BOX,4+1+len(LABELS)),dtype=np.float)                # desired network output\n",
    "        else :\n",
    "          y_batch = np.zeros((n, GRID_H, GRID_W,4+1+len(LABELS)),dtype=np.float)                # desired network output\n",
    "        instance_count=0\n",
    "        for train_instance in train_imgs:\n",
    "            # augment input image and fix object's position and size\n",
    "            #img, all_objs = self.aug_image(train_instance, jitter=self.jitter)\n",
    "            image_name = train_instance['filename']\n",
    "            img = cv2.imread(image_name)\n",
    "            img = cv2.resize(img, (IMAGE_H,IMAGE_W))\n",
    "            img = img[:,:,::-1]\n",
    "            img_w=train_instance['height']\n",
    "            img_h=train_instance['width']\n",
    "            all_objs = train_instance['object']\n",
    "            # construct output from object's x, y, w, h\n",
    "            true_box_index = 0\n",
    "            anchors = [[0, 0, ANCHORS[2*i], ANCHORS[2*i+1]] for i in range(int(len(ANCHORS)//2))]\n",
    "            for obj in all_objs:\n",
    "                no_gridx=float(IMAGE_W / GRID_W)\n",
    "                no_gridy=float(IMAGE_H /GRID_H)\n",
    "                if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin'] and obj['name'] in LABELS:\n",
    "                    center_x = .5*(obj['xmin'] + obj['xmax'])\n",
    "                    center_x = center_x/no_gridx\n",
    "                    center_y = .5*(obj['ymin'] + obj['ymax'])\n",
    "                    center_y=center_y/no_gridy\n",
    "                    grid_x = int(np.floor(center_x))\n",
    "                    grid_y = int(np.floor(center_y))\n",
    "                    #center_x-=grid_x\n",
    "                    #center_y-=grid_y\n",
    "                    if grid_x < GRID_W and grid_y < GRID_H:\n",
    "                        obj_indx  = LABELS.index(obj['name'])\n",
    "                        center_w = (obj['xmax'] - obj['xmin'])/no_gridx #/ (float(self.config['IMAGE_W'])# / self.config['GRID_W']) # unit: grid cell\n",
    "                        center_h = (obj['ymax'] - obj['ymin'])/no_gridy #/ (float(self.config['IMAGE_H'])# / self.config['GRID_H']) # unit: grid cell\n",
    "                        center_w=center_w\n",
    "                        center_h=center_h\n",
    "                        \n",
    "                        box = [center_x, center_y, center_w, center_h]\n",
    "\n",
    "                        # find the anchor that best predicts this box#Change :Hasib\n",
    "                        best_anchor = -1\n",
    "                        max_iou     = -1\n",
    "                        \n",
    "                        shifted_box = [0, 0, center_w, center_h]\n",
    "                        \n",
    "                        for i in range(len(anchors)):\n",
    "                            anchor = anchors[i]\n",
    "                            iou    = bbox_iou(shifted_box, anchor)\n",
    "                            \n",
    "                            if max_iou < iou:\n",
    "                                best_anchor = i\n",
    "                                max_iou     = iou\n",
    "                      \n",
    "                        # assign ground truth x, y, w, h, confidence and class probs to y_batch\n",
    "                        if anc_box==True:\n",
    "                          y_batch[instance_count, grid_y, grid_x, best_anchor,0:4] = box\n",
    "                          y_batch[instance_count, grid_y, grid_x, best_anchor,4  ] = 1.\n",
    "                          y_batch[instance_count, grid_y, grid_x, best_anchor,5+obj_indx] = 1\n",
    "                        else :\n",
    "                          y_batch[instance_count, grid_y, grid_x,0:4] = box\n",
    "                          y_batch[instance_count, grid_y, grid_x,4  ] = 1.\n",
    "                          y_batch[instance_count, grid_y, grid_x,5+obj_indx] = 1\n",
    "\n",
    "                        # assign the true box to b_batch\n",
    "                        #b_batch[instance_count, 0, 0, 0, true_box_index] = box#Change: Hasib\n",
    "                        \n",
    "                        #true_box_index += 1\n",
    "                        #true_box_index = true_box_index % self.config['TRUE_BOX_BUFFER']\n",
    "                            \n",
    "            # assign input image to x_batch\n",
    "            x_batch[instance_count] = img/255\n",
    "\n",
    "            # increase instance counter in current batch\n",
    "            instance_count += 1  \n",
    "\n",
    "        #print(' new batch created', idx)\n",
    "\n",
    "        return x_batch, y_batch\n",
    "\n",
    "import csv\n",
    "\n",
    "def read_data(dataset):\n",
    "  f=open(dataset+'/label.csv')\n",
    "  file=csv.reader(f,delimiter=',')\n",
    "  data=[]\n",
    "  i=0\n",
    "  sc=416.0\n",
    "  for line in file:\n",
    "      dt=line\n",
    "      H=dt[0]\n",
    "      W=dt[1]\n",
    "      xmin=(float(dt[2]))/sc\n",
    "      ymin=(float(dt[3]))/sc\n",
    "      xmax=(float(dt[4]))/sc\n",
    "      ymax=(float(dt[5]))/sc\n",
    "\n",
    "      output={\n",
    "          'filename':dataset+'/images/'+str(i)+'.jpg',\n",
    "          'height':H,\n",
    "          'width':W,\n",
    "          'object':[{'name':'None',\n",
    "          'xmin':xmin*IMAGE_W,\n",
    "          'ymin':ymin*IMAGE_H,\n",
    "          'xmax':xmax*IMAGE_W,\n",
    "          'ymax':ymax*IMAGE_H}]\n",
    "          }\n",
    "\n",
    "      data.append(output)\n",
    "      i=i+1\n",
    "  return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-sSJbnsw8Vu"
   },
   "outputs": [],
   "source": [
    "\n",
    "data_dir='/content/drive/My Drive/CNN_Basic/'\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "def read_content(xml_file: str):\n",
    "    objs=[]\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    list_with_all_boxes = []\n",
    "    filename = root.find('filename').text\n",
    "    size=root.find('size')\n",
    "    img_h=int(size.find('height').text)\n",
    "    img_w=int(size.find('width').text)\n",
    "    print(img_h)\n",
    "    for boxes in root.iter('object'):\n",
    "        \n",
    "        name = boxes.find('name').text\n",
    "        ymin, xmin, ymax, xmax = None, None, None, None\n",
    "        \n",
    "        for box in boxes.findall(\"bndbox\"):\n",
    "            ymin = int(box.find(\"ymin\").text)\n",
    "            xmin = int(box.find(\"xmin\").text)\n",
    "            ymax = int(box.find(\"ymax\").text)\n",
    "            xmax = int(box.find(\"xmax\").text)\n",
    "        wf=IMAGE_W/img_w\n",
    "        hf=IMAGE_H/img_h\n",
    "        obj={'name':name,\n",
    "          'xmin':xmin*wf,\n",
    "          'ymin':ymin*hf,\n",
    "          'xmax':xmax*wf,\n",
    "          'ymax':ymax*hf}\n",
    "        objs.append(obj)\n",
    "        \n",
    "    out={\n",
    "          'filename':data_dir+'VOC_Images/'+filename,\n",
    "          'height':img_h,\n",
    "          'width':img_w,\n",
    "          'object':objs\n",
    "    }\n",
    "        \n",
    "    return filename, list_with_all_boxes,out\n",
    "  \n",
    "import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "save=False\n",
    "if save==True:\n",
    "  fnames=[]\n",
    "  all_data=[]\n",
    "  i=0\n",
    "  \n",
    "  for file in glob.glob(data_dir+'Annotations/*'):\n",
    "    i+=1\n",
    "    print(i)\n",
    "    _,_,obj=read_content(file)\n",
    "    #print(data)\n",
    "    #break\n",
    "    #fname, boxes, objs = read_content(file)\n",
    "    #fnames.append(fname)\n",
    "    all_data.append(obj)\n",
    " \n",
    "  #df=pd.DataFrame([fnames,obj_list],index=['fname','objs']).transpose()\n",
    "  #df=df.sample(frac=1,random_state=10).reset_index(drop=True)\n",
    "  #n=len(df)\n",
    "  #split=int(0.8*n)\n",
    "  #train_data=df.loc[:split]\n",
    "  #val_data=df.loc[split:].reset_index(drop=True)\n",
    "  import pickle\n",
    "  f=open(data_dir+'_VOC_dfs','wb')\n",
    "  pickle.dump(all_data,f)\n",
    "  f.close()\n",
    "import pickle\n",
    "f=open(data_dir+'_VOC_dfs','rb')\n",
    "all_data=pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LSzzHNCSbIPy"
   },
   "source": [
    "### Train Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xz2kN4COaIVh"
   },
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "  optimizer = Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\t#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
    "\t#optimizer = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "  model.compile(loss=yolo_loss_1, optimizer=optimizer,metrics=['accuracy'])\n",
    "  if anc_box==True:\n",
    "    model.compile(loss=custom_loss, optimizer=optimizer,metrics=['accuracy'])\n",
    "  history=model.fit(x_train, y_train,batch_size=20,epochs=50,validation_data=(x_test,y_test),shuffle=True)\n",
    "\t#history=model.fit_generator(generator= train_batch, \n",
    "\t\t\t\t\t\t#steps_per_epoch  = len(train_batch), \n",
    "\t\t\t\t\t\t#epochs           = 60, \n",
    "\t\t\t\t\t\t#verbose          = 1,\n",
    "\t\t\t\t\t\t#validation_data  = valid_batch,\n",
    "\t\t\t\t\t\t#validation_steps = len(valid_batch),\n",
    "\t\t\t\t\t\t#callbacks        = [early_stop], \n",
    "\t\t\t\t\t\t#max_queue_size   = 3)\n",
    "  plt.plot(history.history['acc'])\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.title('model accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'test'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  # summarize history for loss\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "  plt.title('model loss')\n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'test'], loc='upper left')\n",
    "  plt.show()\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14023,
     "status": "ok",
     "timestamp": 1562823140352,
     "user": {
      "displayName": "irfan hasib",
      "photoUrl": "https://lh4.googleusercontent.com/-6rVnRThUoWk/AAAAAAAAAAI/AAAAAAAADsk/X6dBOaUVMS4/s64/photo.jpg",
      "userId": "16061096143782894681"
     },
     "user_tz": -360
    },
    "id": "Md5yqGs0ZURg",
    "outputId": "18fb074f-7747-4ce8-8e49-f97736631dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 416, 416, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 416, 416, 32) 864         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)     (None, 416, 416, 32) 128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_67 (LeakyReLU)      (None, 416, 416, 32) 0           norm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 208, 208, 32) 0           leaky_re_lu_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 208, 208, 64) 18432       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)     (None, 208, 208, 64) 256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_68 (LeakyReLU)      (None, 208, 208, 64) 0           norm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 104, 104, 64) 0           leaky_re_lu_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 104, 104, 128 73728       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_3 (BatchNormalization)     (None, 104, 104, 128 512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_69 (LeakyReLU)      (None, 104, 104, 128 0           norm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 104, 104, 64) 8192        leaky_re_lu_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_4 (BatchNormalization)     (None, 104, 104, 64) 256         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_70 (LeakyReLU)      (None, 104, 104, 64) 0           norm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 104, 104, 128 73728       leaky_re_lu_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_5 (BatchNormalization)     (None, 104, 104, 128 512         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_71 (LeakyReLU)      (None, 104, 104, 128 0           norm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 52, 52, 128)  0           leaky_re_lu_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 52, 52, 256)  294912      max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_6 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_72 (LeakyReLU)      (None, 52, 52, 256)  0           norm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 52, 52, 128)  32768       leaky_re_lu_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_7 (BatchNormalization)     (None, 52, 52, 128)  512         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_73 (LeakyReLU)      (None, 52, 52, 128)  0           norm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 52, 52, 256)  294912      leaky_re_lu_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_8 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_74 (LeakyReLU)      (None, 52, 52, 256)  0           norm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 26, 26, 256)  0           leaky_re_lu_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 26, 26, 512)  1179648     max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_9 (BatchNormalization)     (None, 26, 26, 512)  2048        conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_75 (LeakyReLU)      (None, 26, 26, 512)  0           norm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_10 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_76 (LeakyReLU)      (None, 26, 26, 256)  0           norm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_11 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_77 (LeakyReLU)      (None, 26, 26, 512)  0           norm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_12 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_78 (LeakyReLU)      (None, 26, 26, 256)  0           norm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_13 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_79 (LeakyReLU)      (None, 26, 26, 512)  0           norm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 13, 13, 512)  0           leaky_re_lu_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 13, 13, 1024) 4718592     max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_14 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_80 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_15 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_81 (LeakyReLU)      (None, 13, 13, 512)  0           norm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_16 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_82 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_17 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_83 (LeakyReLU)      (None, 13, 13, 512)  0           norm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_18 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_84 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_19 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_19 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_21 (Conv2D)                (None, 26, 26, 64)   32768       leaky_re_lu_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_85 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_21 (BatchNormalization)    (None, 26, 26, 64)   256         conv_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_87 (LeakyReLU)      (None, 26, 26, 64)   0           norm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_20 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 13, 13, 256)  0           leaky_re_lu_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_86 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 13, 13, 1280) 0           lambda_4[0][0]                   \n",
      "                                                                 leaky_re_lu_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_22 (Conv2D)                (None, 13, 13, 1024) 11796480    concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_22 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_88 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_23 (Conv2D)                (None, 13, 13, 125)  128125      leaky_re_lu_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 13, 13, 5, 25 0           conv_23[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 50,676,061\n",
      "Trainable params: 50,655,389\n",
      "Non-trainable params: 20,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "root='/content/drive/My Drive/Data/'\n",
    "path_wts=root+'yolo.weights'\n",
    "path_wts_final=root+'yolo_minimal_anc_500.h5'\n",
    "path_data=root+'np_500'\n",
    "path_pred=root+'/np_500/images/'\n",
    "  \n",
    "if train==True:\n",
    "  #data=read_data(path_data)\n",
    "  \n",
    "  train_imgs=all_data[:400]\n",
    "  valid_imgs=all_data[400:460]\n",
    "  \n",
    "  x_train,y_train = Batch_Gen(train_imgs)\n",
    "  x_test,y_test = Batch_Gen(valid_imgs)\n",
    "model=build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 742998,
     "status": "ok",
     "timestamp": 1562823869375,
     "user": {
      "displayName": "irfan hasib",
      "photoUrl": "https://lh4.googleusercontent.com/-6rVnRThUoWk/AAAAAAAAAAI/AAAAAAAADsk/X6dBOaUVMS4/s64/photo.jpg",
      "userId": "16061096143782894681"
     },
     "user_tz": -360
    },
    "id": "DKBYfi42VnXe",
    "outputId": "afb1c882-3192-4bb0-db43-c68c9b9e2843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400 samples, validate on 60 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 20s 50ms/step - loss: nan - acc: 0.0096 - val_loss: nan - val_acc: 0.0093\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0120 - val_loss: nan - val_acc: 0.0104\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 13s 34ms/step - loss: nan - acc: 0.0090 - val_loss: nan - val_acc: 0.0089\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 13s 34ms/step - loss: nan - acc: 0.0063 - val_loss: nan - val_acc: 0.0073\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0064 - val_loss: nan - val_acc: 0.0064\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0072 - val_loss: nan - val_acc: 0.0062\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0082 - val_loss: nan - val_acc: 0.0065\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0104 - val_loss: nan - val_acc: 0.0062\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0126 - val_loss: nan - val_acc: 0.0072\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0153 - val_loss: nan - val_acc: 0.0084\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0182 - val_loss: nan - val_acc: 0.0100\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0219 - val_loss: nan - val_acc: 0.0125\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0256 - val_loss: nan - val_acc: 0.0154\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0294 - val_loss: nan - val_acc: 0.0181\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0324 - val_loss: nan - val_acc: 0.0209\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0329 - val_loss: nan - val_acc: 0.0239\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0349 - val_loss: nan - val_acc: 0.0264\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0350 - val_loss: nan - val_acc: 0.0287\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0370 - val_loss: nan - val_acc: 0.0310\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0375 - val_loss: nan - val_acc: 0.0325\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0368 - val_loss: nan - val_acc: 0.0338\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0370 - val_loss: nan - val_acc: 0.0353\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0379 - val_loss: nan - val_acc: 0.0366\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0384 - val_loss: nan - val_acc: 0.0371\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0377 - val_loss: nan - val_acc: 0.0386\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0372 - val_loss: nan - val_acc: 0.0396\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0371 - val_loss: nan - val_acc: 0.0396\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0366 - val_loss: nan - val_acc: 0.0402\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0362 - val_loss: nan - val_acc: 0.0404\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0375 - val_loss: nan - val_acc: 0.0404\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0361 - val_loss: nan - val_acc: 0.0386\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0378 - val_loss: nan - val_acc: 0.0381\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0384 - val_loss: nan - val_acc: 0.0387\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0386 - val_loss: nan - val_acc: 0.0395\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0371 - val_loss: nan - val_acc: 0.0392\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0367 - val_loss: nan - val_acc: 0.0400\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0369 - val_loss: nan - val_acc: 0.0399\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0364 - val_loss: 3.1086 - val_acc: 0.0406\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0366 - val_loss: nan - val_acc: 0.0402\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0359 - val_loss: nan - val_acc: 0.0409\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0377 - val_loss: nan - val_acc: 0.0420\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0375 - val_loss: nan - val_acc: 0.0415\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0366 - val_loss: nan - val_acc: 0.0409\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0376 - val_loss: nan - val_acc: 0.0409\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0364 - val_loss: nan - val_acc: 0.0393\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0370 - val_loss: nan - val_acc: 0.0410\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0382 - val_loss: nan - val_acc: 0.0413\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0370 - val_loss: nan - val_acc: 0.0410\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0353 - val_loss: nan - val_acc: 0.0406\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: nan - acc: 0.0353 - val_loss: nan - val_acc: 0.0399\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x+NM6oiOCeRXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if train==True:\n",
    "\tmodel=load_weights(model,path_wts)\n",
    "\tmodel=train_model(model)\n",
    "if train==False:\n",
    "\tmodel.load_weights(path_wts_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6KMduvZAbNMY"
   },
   "source": [
    "### Predicion Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "15upCTbggjjjGTtdZ00odt0VSTbBrTO0i"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16930,
     "status": "error",
     "timestamp": 1562824592673,
     "user": {
      "displayName": "irfan hasib",
      "photoUrl": "https://lh4.googleusercontent.com/-6rVnRThUoWk/AAAAAAAAAAI/AAAAAAAADsk/X6dBOaUVMS4/s64/photo.jpg",
      "userId": "16061096143782894681"
     },
     "user_tz": -360
    },
    "id": "S6ZO-9qLaNBN",
    "outputId": "70174882-7588-41e9-c56e-b6a95918e7b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _softmax(x, axis=-1, t=-100.):\n",
    "    x = x - np.max(x)\n",
    "    \n",
    "    if np.min(x) < t:\n",
    "        x = x/np.min(x)*t\n",
    "        \n",
    "    e_x = np.exp(x)\n",
    "    \n",
    "    return e_x / e_x.sum(axis, keepdims=True)\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def decode_netout_anc(netout, anchors, nb_class, obj_threshold=0.3, nms_threshold=0.3):\n",
    "    #grid_h, grid_w, nb_box = netout.shape[:3]\n",
    "    grid_h, grid_w = netout.shape[:2]\n",
    "\n",
    "    boxes = []\n",
    "    \n",
    "    # decode the output by the network\n",
    "    netout[..., 4]  = _sigmoid(netout[..., 4])\n",
    "    netout[..., 5:] = netout[..., 4][..., np.newaxis] * _softmax(netout[..., 5:])\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_threshold\n",
    "    \n",
    "    for row in range(grid_h):\n",
    "        for col in range(grid_w):\n",
    "            for b in range(BOX):\n",
    "                # from 4th element onwards are confidence and class classes\n",
    "                classes = netout[row,col,b,5:]\n",
    "                #classes = netout[row,col,5:]\n",
    "                confidence = netout[row,col,b,4]\n",
    "                if np.sum(classes) > 0:\n",
    "                    # first 4 elements are x, y, w, and h\n",
    "                    #x, y, w, h = netout[row,col,b,:4]\n",
    "                    x, y, w, h = netout[row,col,b,:4]\n",
    "                    #print(col,_sigmoid(x-col),row,_sigmoid(y),w,h)\n",
    "                    x = (col + _sigmoid(x)) / grid_w # center position, unit: image width\n",
    "                    y = (row + _sigmoid(y)) / grid_h # center position, unit: image height\n",
    "                    w = ANCHORS[2 * b + 0] * np.exp(w) / grid_w # unit: image width\n",
    "                    h = ANCHORS[2 * b + 1] * np.exp(h) / grid_h # unit: image height\n",
    "                    #print(x,y,w,h)\n",
    "                    classes=np.argmax(classes)\n",
    "                    \n",
    "                    box = (x-w/2, y-h/2, x+w/2, y+h/2, confidence, classes)\n",
    "                    box = (x-w/2, y-h/2, x+w/2, y+h/2, confidence, classes)\n",
    "                    if abs(box[0])<=1 and abs(box[1])<=1 and box[2]<=1 and box[3]<=1 :\n",
    "                      if (box[0])>=0 and (box[1])>=0 and box[2]>=0 and box[3]>=0 :\n",
    "                        boxes.append(box)\n",
    "                    \n",
    "\n",
    "                        \n",
    "    indx=np.argsort([box[4] for box in boxes])\n",
    "    f_boxes=[]\n",
    "    #indx=reversed(indx)\n",
    "    if len(indx)>=3:\n",
    "      for i in range(1,2):\n",
    "        ind=indx[-1*i]\n",
    "        f_boxes.append(boxes[ind])\n",
    "    else:\n",
    "      f_boxes=boxes\n",
    "    return f_boxes    \n",
    "    \n",
    "def decode_netout_1(netout, anchors, nb_class, obj_threshold=0.3, nms_threshold=0.3):\n",
    "    #grid_h, grid_w, nb_box = netout.shape[:3]\n",
    "    grid_h, grid_w = netout.shape[:2]\n",
    "\n",
    "    boxes = []\n",
    "    \n",
    "    # decode the output by the network\n",
    "    netout[..., 4]  = _sigmoid(netout[..., 4])\n",
    "    netout[..., 5:] = netout[..., 4][..., np.newaxis] * _softmax(netout[..., 5:])\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_threshold\n",
    "    print('A')\n",
    "    for row in range(grid_h):\n",
    "        for col in range(grid_w):\n",
    "            #for b in range(BOX):\n",
    "                # from 4th element onwards are confidence and class classes\n",
    "                classes = netout[row,col,5:]\n",
    "                #classes = netout[row,col,5:]\n",
    "                confidence = netout[row,col,4]\n",
    "                if np.sum(classes) > 0:\n",
    "                    # first 4 elements are x, y, w, and h\n",
    "                    #x, y, w, h = netout[row,col,b,:4]\n",
    "                    x, y, w, h = netout[row,col,:4]\n",
    "                    #print(col,_sigmoid(x-col),row,_sigmoid(y),w,h)\n",
    "                    x = x*(32/416) # center position, unit: image width\n",
    "                    y = y*(32/416) # center position, unit: image height\n",
    "                    w = w*(32/416) # unit: image width\n",
    "                    h = h*(32/416) # unit: image height\n",
    "                    #print(x,y,w,h)\n",
    "                    classes=np.argmax(classes)\n",
    "                    \n",
    "                    box = (x-w/2, y-h/2, x+w/2, y+h/2, confidence, classes)\n",
    "                    if abs(box[0])<=1 and abs(box[1])<=1 and box[2]<=1 and box[3]<=1 :\n",
    "                      if (box[0])>=0 and (box[1])>=0 and box[2]>=0 and box[3]>=0 :\n",
    "                        boxes.append(box)\n",
    "                    \n",
    "                      \n",
    "    \n",
    "    indx=np.argsort([box[4] for box in boxes])\n",
    "    # remove the boxes which are less likely than a obj_threshold\n",
    "    #obj_threshold=0\n",
    "    #print(boxes)\n",
    "    #for box in boxes:\n",
    "    #  if box[4]>obj_threshold:\n",
    "    #      obj_threshold=box[4]\n",
    "    #boxes = [box for box in boxes if box[4] >= obj_threshold-0.1]\n",
    "    \n",
    "    f_boxes=[]\n",
    "    #indx=reversed(indx)\n",
    "    if len(indx)>=3:\n",
    "      for i in range(1,2):\n",
    "        ind=indx[-1*i]\n",
    "        f_boxes.append(boxes[ind])\n",
    "    else:\n",
    "      f_boxes=boxes\n",
    "    print('B')\n",
    "    return f_boxes    \n",
    "\n",
    "def draw_boxes_1(image, boxes, labels,t_lbl=None):\n",
    "    image_h, image_w, _ = image.shape\n",
    "\n",
    "    for box in boxes:\n",
    "        xmin = int(box[0]*image_w)\n",
    "        ymin = int(box[1]*image_h)\n",
    "        xmax = int(box[2]*image_w)\n",
    "        ymax = int(box[3]*image_h)\n",
    "        x_off=20\n",
    "        y_off=20\n",
    "        print(xmin,ymin,xmax,ymax)\n",
    "        print(box)\n",
    "        cv2.rectangle(image, (xmin-x_off,ymin-y_off), (xmax+x_off,ymax+y_off), (255,0,0), 3)\n",
    "        cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (0,255,0), 3)\n",
    "        if t_lbl !=None:\n",
    "          cv2.rectangle(image, (t_lbl[0],t_lbl[1]), (t_lbl[2],t_lbl[3]), (0,0,255), 3)\n",
    "        cv2.putText(image, \n",
    "                    labels[box[5]] + ' ' + str(box[4]), \n",
    "                    (xmin, ymin - 13), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    1e-3 * image_h, \n",
    "                    (0,255,0), 1)\n",
    "        \n",
    "    return image\n",
    "\n",
    "\"\"\"# Perform detection on image\"\"\"\n",
    "error=0\n",
    "count=0\n",
    "import pandas as pd\n",
    "lbls=pd.read_csv(path_data+'/label.csv',names=[0,1,2,3,4,5])\n",
    "  \n",
    "for i in range(400,450):\n",
    "  count+=1\n",
    "  image = cv2.imread(path_pred+str(i)+'.jpg')\n",
    "  H_off=int(image.shape[0]*0.1)\n",
    "  W_off=int(image.shape[1]*0.1)\n",
    "  #image=image[H_off:-1*H_off,W_off:-1*W_off,:]\n",
    "  dummy_array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))\n",
    "\n",
    "  \n",
    "\n",
    "  input_image = cv2.resize(image, (416, 416))\n",
    "  input_image = input_image / 255.\n",
    "  input_image = input_image[:,:,::-1]\n",
    "  input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "  netout = model.predict(input_image)\n",
    "  #print(netout[0,:,:,0:2])\n",
    "\n",
    "\n",
    "  if anc_box==True:\n",
    "    boxes = decode_netout_anc(netout[0], \n",
    "                        obj_threshold=.60,\n",
    "                        nms_threshold=.90,\n",
    "                        anchors=ANCHORS, \n",
    "                        nb_class=CLASS)\n",
    "  else:\n",
    "    boxes = decode_netout_1(netout[0], \n",
    "                        obj_threshold=0.60,\n",
    "                        nms_threshold=.90,\n",
    "                        anchors=ANCHORS, \n",
    "                        nb_class=CLASS)\n",
    "  \n",
    "  true_lb=list(lbls.loc[i,2:5])\n",
    "  err=np.sum(np.square(np.array(true_lb)-np.array(boxes[0][:4])*416))\n",
    "  if err<100:\n",
    "    error+=err\n",
    "  else:\n",
    "    error+=100\n",
    "  #boxex.appned(true_lb)\n",
    "  image = draw_boxes_1(image, boxes, LABELS,true_lb)\n",
    "  plt.figure(figsize=(10,10))\n",
    "  plt.imshow(image[:,:,::-1]); plt.show()\n",
    "  print(err)\n",
    "print('mean error',error/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aJ8mkUunpBaK"
   },
   "outputs": [],
   "source": [
    "#model.save('/content/drive/My Drive/Data/yolo_minimal_anc_500.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v55OMypTzvzQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lbls=pd.read_csv(path_data+'/label.csv',names=[0,1,2,3,4,5])\n",
    "true_lb=list(lbls.loc[0,0:5])\n",
    "true_lb"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Minimal_yolo_v_3_functioned",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
