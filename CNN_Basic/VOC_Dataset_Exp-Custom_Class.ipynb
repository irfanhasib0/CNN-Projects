{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOC Dataset :  train , validation and test data dumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import pickle\n",
    "root='D:/VOC/'\n",
    "train_dir='D:/VOC/VOC2007/'\n",
    "test_dir='D:/VOC/VOC2007_test/'\n",
    "data_save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_ALL=['person', 'bird', 'cat', 'cow', 'dog', 'horse', 'sheep','aeroplane', 'bicycle',\n",
    "         'boat', 'bus', 'car', 'motorbike', 'train', 'bottle', 'chair','diningtable',\n",
    "         'pottedplant', 'sofa', 'tvmonitor']\n",
    "\n",
    "f=open('D:/VOC/labels_voc','wb')\n",
    "pickle.dump(LABELS_ALL,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'cow',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'sheep',\n",
       " 'aeroplane',\n",
       " 'bicycle',\n",
       " 'boat',\n",
       " 'bus',\n",
       " 'car',\n",
       " 'motorbike',\n",
       " 'train',\n",
       " 'bottle',\n",
       " 'chair',\n",
       " 'diningtable',\n",
       " 'pottedplant',\n",
       " 'sofa',\n",
       " 'tvmonitor']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5011\n",
      "4952\n",
      "4952\n"
     ]
    }
   ],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "def read_content(xml_file,_dir):\n",
    "    objs=[]\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    list_with_all_boxes = []\n",
    "    filename = root.find('filename').text\n",
    "    size=root.find('size')\n",
    "    img_h=int(size.find('height').text)\n",
    "    img_w=int(size.find('width').text)\n",
    "    for boxes in root.iter('object'):\n",
    "        \n",
    "        name = boxes.find('name').text\n",
    "        ymin, xmin, ymax, xmax = None, None, None, None\n",
    "        \n",
    "        for box in boxes.findall(\"bndbox\"):\n",
    "            ymin = int(box.find(\"ymin\").text)\n",
    "            xmin = int(box.find(\"xmin\").text)\n",
    "            ymax = int(box.find(\"ymax\").text)\n",
    "            xmax = int(box.find(\"xmax\").text)\n",
    "        wf=1/img_w\n",
    "        hf=1/img_h\n",
    "        obj={'name':name,\n",
    "          'xmin':xmin*wf,\n",
    "          'ymin':ymin*hf,\n",
    "          'xmax':xmax*wf,\n",
    "          'ymax':ymax*hf}\n",
    "        objs.append(obj)\n",
    "        \n",
    "    out={\n",
    "          'filename':'JPEGImages/'+filename,\n",
    "          'height':img_h,\n",
    "          'width':img_w,\n",
    "          'object':objs\n",
    "    }\n",
    "        \n",
    "    return filename, list_with_all_boxes,out\n",
    "\n",
    "\n",
    "if data_save==True:\n",
    "  fnames=[]\n",
    "  train_data=[]\n",
    "  test_data=[]\n",
    "  i=0\n",
    "    \n",
    "  for file in glob.glob(train_dir+'Annotations/*'):\n",
    "    i+=1\n",
    "    \n",
    "    _,_,obj=read_content(file,train_dir)\n",
    "    train_data.append(obj)\n",
    "\n",
    "  i=0\n",
    "  for file in glob.glob(test_dir+'Annotations/*'):\n",
    "    i+=1\n",
    "    \n",
    "    _,_,obj=read_content(file,test_dir)\n",
    "    test_data.append(obj)\n",
    "  print(len(train_data)) \n",
    "  f=open(root+'train_VOC_dfs','wb')\n",
    "  pickle.dump(train_data,f)\n",
    "  f.close()\n",
    "  print(len(test_data)) \n",
    "  f=open(root+'val_VOC_dfs','wb')\n",
    "  pickle.dump(test_data,f)\n",
    "  f.close()\n",
    "  print(len(test_data)) \n",
    "  f=open(root+'test_VOC_dfs','wb')\n",
    "  pickle.dump(test_data,f)\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/VOC/VOC2007/Annotations/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir+'Annotations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Minimal_yolo_v_3_functioned",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
