{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO Dataset :  train , validation and test data dumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import glob\n",
    "import pickle\n",
    "root='D:/COCO/'\n",
    "#f=open(,'r')\n",
    "groups=['train','val','test']\n",
    "files=[root+'annot_2017/instances_train2017.json',\n",
    "       root+'annot_2017/instances_val2017.json',\n",
    "       root+'annot_2017/image_info_test-dev2017.json']\n",
    "\n",
    "img_files=[root+'train2017/train2017/*',\n",
    "           root+'val2017/val2017/*',\n",
    "           root+'test2017/test2017/*']\n",
    "\n",
    "annot_dicts=[]\n",
    "for file in files:\n",
    "    f=open(file,'r')\n",
    "    annot_dict=json.load(f)\n",
    "    annot_dicts.append(annot_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS={}\n",
    "for cat in annot_dicts[0]['categories']:\n",
    "    LABELS[cat['id']]=cat['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(root+'labels_coco','wb')\n",
    "pickle.dump(LABELS,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_annot(annot_dict,img_file,group):\n",
    "    \n",
    "    images=annot_dict['images']\n",
    "    images_dict={}\n",
    "    if group !='test': \n",
    "        annotations=annot_dict['annotations']\n",
    "        for image in images:\n",
    "            images_dict[image['id']]=[image['file_name'],image['width'],image['height']]\n",
    "        annots_dict={}\n",
    "        for annot in annotations:\n",
    "            annots_dict[annot['image_id']]=[]\n",
    "        for annot in annotations:\n",
    "            annots_dict[annot['image_id']].append(annot)\n",
    "        train_images={}\n",
    "        for _id in annots_dict.keys():\n",
    "            train_img={}\n",
    "            image=images_dict[_id]\n",
    "            annots=annots_dict[_id]\n",
    "            train_img['id']=_id\n",
    "            train_img['filename']=image[0]\n",
    "            train_img['width']=image[1]\n",
    "            train_img['height']=image[2]\n",
    "            objs=[]\n",
    "            wf=1/image[1]\n",
    "            hf=1/image[2]\n",
    "            for annot in annots:\n",
    "                if annot['iscrowd']==0:\n",
    "                   obj={}\n",
    "                   bbox=annot['bbox']\n",
    "                   obj['name']=LABELS[annot['category_id']]\n",
    "                   obj['xmin']=bbox[0]*wf\n",
    "                   obj['ymin']=bbox[1]*hf\n",
    "                   obj['xmax']=(bbox[0]+bbox[2])*wf\n",
    "                   obj['ymax']=(bbox[1]+bbox[3])*hf\n",
    "                   objs.append(obj)\n",
    "            train_img['object']=objs\n",
    "            train_images[image[0]]=train_img\n",
    "        fnames=[]  \n",
    "        _data=[] \n",
    "        for i,file in enumerate(glob.glob(img_file)):\n",
    "                file_name=file.split('\\\\')[-1]\n",
    "                try:data=train_images[file_name]\n",
    "                except:continue\n",
    "                _data.append(data)\n",
    "    if group=='test':\n",
    "        _data=[]\n",
    "        for i,data in enumerate(images):\n",
    "            data['filename']=data['file_name']\n",
    "            _data.append(data)\n",
    "    print('saving files','len ',len(_data),'fname ',root+group+'_coco_dfs')\n",
    "    f=open(root+group+'_coco_dfs','wb')\n",
    "    pickle.dump(_data,f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving files len  117266 fname  D:/COCO/train_coco_dfs\n",
      "saving files len  4952 fname  D:/COCO/val_coco_dfs\n",
      "saving files len  20288 fname  D:/COCO/test_coco_dfs\n"
     ]
    }
   ],
   "source": [
    "for annot_dict,img_file,group in zip(annot_dicts,img_files,groups):\n",
    "                   save_annot(annot_dict,img_file,group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_data(dataset):\n",
    "  f=open(dataset+'/label.csv')\n",
    "  file=csv.reader(f,delimiter=',')\n",
    "  data=[]\n",
    "  i=0\n",
    "  sc=416.0\n",
    "  for line in file:\n",
    "      dt=line\n",
    "      H=dt[0]\n",
    "      W=dt[1]\n",
    "      xmin=(float(dt[2]))/sc\n",
    "      ymin=(float(dt[3]))/sc\n",
    "      xmax=(float(dt[4]))/sc\n",
    "      ymax=(float(dt[5]))/sc\n",
    "\n",
    "      output={\n",
    "          'filename':dataset+'/images/'+str(i)+'.jpg',\n",
    "          'height':H,\n",
    "          'width':W,\n",
    "          'object':[{'name':'None',\n",
    "          'xmin':xmin*IMAGE_W,\n",
    "          'ymin':ymin*IMAGE_H,\n",
    "          'xmax':xmax*IMAGE_W,\n",
    "          'ymax':ymax*IMAGE_H}]\n",
    "          }\n",
    "\n",
    "      data.append(output)\n",
    "      i=i+1\n",
    "  return data\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Minimal_yolo_v_3_functioned",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
