{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO Dataset :  train , validation and test data dumping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "root='D:/COCO/'\n",
    "#f=open(,'r')\n",
    "groups=['train','val','test']\n",
    "files=[root+'annot_2017/instances_train2017.json',\n",
    "       root+'annot_2017/instances_val2017.json',\n",
    "       root+'annot_2017/image_info_test-dev2017.json']\n",
    "\n",
    "img_files=[root+'train2017/train2017/*',\n",
    "           root+'val2017/val2017/*',\n",
    "           root+'test2017/test2017/*']\n",
    "\n",
    "annot_dicts=[]\n",
    "for file in files:\n",
    "    f=open(file,'r')\n",
    "    annot_dict=json.load(f)\n",
    "    annot_dicts.append(annot_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_road=['person','bicycle','car','motorcycle','airplane','bus','train','truck','boat','traffic light','stop sign']\n",
    "#_home=['chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors']#, 'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_ALL={}\n",
    "for cat in annot_dicts[0]['categories']:\n",
    "    LABELS_ALL[cat['id']]=cat['name']\n",
    "LABELS={}\n",
    "for cat in annot_dicts[0]['categories']:\n",
    "    if cat['name'] not in _road:\n",
    "        continue\n",
    "    LABELS[cat['id']]=cat['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(root+'_labels_coco_road','wb')\n",
    "pickle.dump(LABELS,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_annot(annot_dict,img_file,group):\n",
    "    obj_count=pd.Series([0]*len(_road),index=_road)\n",
    "    images=annot_dict['images']\n",
    "    images_dict={}\n",
    "    if group !='test': \n",
    "        annotations=annot_dict['annotations']\n",
    "        for image in images:\n",
    "            images_dict[image['id']]=[image['file_name'],image['width'],image['height']]\n",
    "        annots_dict={}\n",
    "        for annot in annotations:\n",
    "            annots_dict[annot['image_id']]=[]\n",
    "        for annot in annotations:\n",
    "            annots_dict[annot['image_id']].append(annot)\n",
    "        train_images={}\n",
    "        for _id in annots_dict.keys():\n",
    "            train_img={}\n",
    "            image=images_dict[_id]\n",
    "            annots=annots_dict[_id]\n",
    "            train_img['id']=_id\n",
    "            train_img['filename']=image[0]\n",
    "            train_img['width']=image[1]\n",
    "            train_img['height']=image[2]\n",
    "            _objs=[]\n",
    "            wf=1/image[1]\n",
    "            hf=1/image[2]\n",
    "            _obj_count=obj_count.copy()\n",
    "            for annot in annots:\n",
    "                if annot['iscrowd']==0:\n",
    "                   obj={}\n",
    "                   bbox=annot['bbox']\n",
    "                   if LABELS_ALL[annot['category_id']] not in _road:\n",
    "                         continue\n",
    "                   \n",
    "                   obj['name']=LABELS[annot['category_id']]\n",
    "                   obj['xmin']=bbox[0]*wf\n",
    "                   obj['ymin']=bbox[1]*hf\n",
    "                   obj['xmax']=(bbox[0]+bbox[2])*wf\n",
    "                   obj['ymax']=(bbox[1]+bbox[3])*hf\n",
    "                   #if _obj_count[obj['name']] >= 10000:\n",
    "                   #      _objs=[]\n",
    "                   #      break\n",
    "                   _objs.append(obj)\n",
    "                   _obj_count[obj['name']]+=1\n",
    "            objs=[]\n",
    "            #for obj in _objs:\n",
    "            #    if _obj_count[obj['name']] <= 5000:\n",
    "            #        objs=_objs\n",
    "            #        obj_count=_obj_count\n",
    "            objs=_objs\n",
    "            obj_count=_obj_count\n",
    "            if len(objs)==0:\n",
    "                continue\n",
    "            train_img['object']=objs\n",
    "            train_images[image[0]]=train_img\n",
    "        fnames=[]  \n",
    "        _data=[] \n",
    "        for i,file in enumerate(glob.glob(img_file)):\n",
    "                file_name=file.split('\\\\')[-1]\n",
    "                try:data=train_images[file_name]\n",
    "                except:continue\n",
    "                _data.append(data)\n",
    "    if group=='test':\n",
    "        _data=[]\n",
    "        for i,data in enumerate(images):\n",
    "            data['filename']=data['file_name']\n",
    "            _data.append(data)\n",
    "    print('saving files','len ',len(_data),'fname ',root+group+'_coco_dfs')\n",
    "    f=open(root+group+'_coco_dfs_road','wb')\n",
    "    pickle.dump(_data,f)\n",
    "    f.close()\n",
    "    return obj_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving files len  75392 fname  D:/COCO/train_coco_dfs\n",
      "person           257253\n",
      "bicycle            7056\n",
      "car               43533\n",
      "motorcycle         8654\n",
      "airplane           5129\n",
      "bus                6061\n",
      "train              4570\n",
      "truck              9970\n",
      "boat              10576\n",
      "traffic light     12842\n",
      "stop sign          1983\n",
      "dtype: int64\n",
      "saving files len  3176 fname  D:/COCO/val_coco_dfs\n",
      "person           10777\n",
      "bicycle            314\n",
      "car               1918\n",
      "motorcycle         367\n",
      "airplane           143\n",
      "bus                283\n",
      "train              190\n",
      "truck              414\n",
      "boat               424\n",
      "traffic light      634\n",
      "stop sign           75\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for annot_dict,img_file,group in zip(annot_dicts[:-1],img_files[:-1],groups[:-1]):\n",
    "                   obj_count=save_annot(annot_dict,img_file,group)\n",
    "                   print(obj_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person           10777\n",
       "bicycle            314\n",
       "car               1918\n",
       "motorcycle         367\n",
       "airplane           143\n",
       "bus                283\n",
       "train              190\n",
       "truck              414\n",
       "boat               424\n",
       "traffic light      634\n",
       "stop sign           75\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_data(dataset):\n",
    "  f=open(dataset+'/label.csv')\n",
    "  file=csv.reader(f,delimiter=',')\n",
    "  data=[]\n",
    "  i=0\n",
    "  sc=416.0\n",
    "  for line in file:\n",
    "      dt=line\n",
    "      H=dt[0]\n",
    "      W=dt[1]\n",
    "      xmin=(float(dt[2]))/sc\n",
    "      ymin=(float(dt[3]))/sc\n",
    "      xmax=(float(dt[4]))/sc\n",
    "      ymax=(float(dt[5]))/sc\n",
    "\n",
    "      output={\n",
    "          'filename':dataset+'/images/'+str(i)+'.jpg',\n",
    "          'height':H,\n",
    "          'width':W,\n",
    "          'object':[{'name':'None',\n",
    "          'xmin':xmin*IMAGE_W,\n",
    "          'ymin':ymin*IMAGE_H,\n",
    "          'xmax':xmax*IMAGE_W,\n",
    "          'ymax':ymax*IMAGE_H}]\n",
    "          }\n",
    "\n",
    "      data.append(output)\n",
    "      i=i+1\n",
    "  return data\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Minimal_yolo_v_3_functioned",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
