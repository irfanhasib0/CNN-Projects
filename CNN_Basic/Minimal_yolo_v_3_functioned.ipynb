{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2hDx1_O_absD"
   },
   "source": [
    "### Initialization Bock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5812,
     "status": "ok",
     "timestamp": 1562823131674,
     "user": {
      "displayName": "irfan hasib",
      "photoUrl": "https://lh4.googleusercontent.com/-6rVnRThUoWk/AAAAAAAAAAI/AAAAAAAADsk/X6dBOaUVMS4/s64/photo.jpg",
      "userId": "16061096143782894681"
     },
     "user_tz": -360
    },
    "id": "h1HPqGKtZdQ8",
    "outputId": "0543c1fe-60df-4bca-cf10-212504dd2dab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irfan\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\irfan\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\irfan\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\irfan\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\irfan\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\irfan\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "colab_run=False\n",
    "anc_box= False\n",
    "train=True\n",
    "if colab_run==True:\n",
    "  !pip install pydrive\n",
    "  from pydrive.auth import GoogleAuth\n",
    "  from pydrive.drive import GoogleDrive\n",
    "  from google.colab import auth\n",
    "  from oauth2client.client import GoogleCredentials\n",
    "\n",
    "  auth.authenticate_user()\n",
    "  gauth = GoogleAuth()\n",
    "  gauth.credentials = GoogleCredentials.get_application_default()\n",
    "  drive = GoogleDrive(gauth)\n",
    "\n",
    "  import os, cv2\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive/')\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os, cv2\n",
    "\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# %matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XcCwnGYHaul2"
   },
   "source": [
    "### Configure Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5eIxqVja27b"
   },
   "source": [
    "### Model Building Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dDHEMWhWZo40"
   },
   "outputs": [],
   "source": [
    "LABELS=['person', 'bird', 'cat', 'cow', 'dog', 'horse', 'sheep','aeroplane', 'bicycle',\n",
    "         'boat', 'bus', 'car', 'motorbike', 'train', 'bottle', 'chair','dining table',\n",
    "         'potted plant', 'sofa', 'tvmonitor']\n",
    "\n",
    "IMAGE_H, IMAGE_W = 416, 416\n",
    "GRID_H,  GRID_W  = 13 , 13\n",
    "BOX              = 5\n",
    "CLASS            = len(LABELS)\n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "OBJ_THRESHOLD    = 0.3#0.5\n",
    "NMS_THRESHOLD    = 0.3#0.45\n",
    "#ANCHORS          = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "ANCHORS          = [ 4.469053,2.148582,10.548851,5.381520,11.420664,9.961033,6.517299,3.699693,2.469196,1.599054]\n",
    "#ANCHORS=[13,13]\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "batch_size       =10\n",
    "WARM_UP_BATCHES  = 0\n",
    "TRUE_BOX_BUFFER  = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJnrCWISZz8S"
   },
   "outputs": [],
   "source": [
    "# the function to implement the orgnization layer (thanks to github.com/allanzelener/YAD2K)\n",
    "def space_to_depth_x2(x):\n",
    "    return tf.space_to_depth(x, block_size=2)\n",
    "\n",
    "def build_model():\n",
    "  input_image = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
    "  true_boxes  = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\n",
    "\n",
    "  # Layer 1\n",
    "  x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "  x = BatchNormalization(name='norm_1')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "  # Layer 2\n",
    "  x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_2')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "  # Layer 3\n",
    "  x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_3')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 4\n",
    "  x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_4')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 5\n",
    "  x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_5')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "  # Layer 6\n",
    "  x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_6')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 7\n",
    "  x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_7')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 8\n",
    "  x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_8')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "  # Layer 9\n",
    "  x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_9')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 10\n",
    "  x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_10')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 11\n",
    "  x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_11')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 12\n",
    "  x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_12')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 13\n",
    "  x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_13')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  skip_connection = x\n",
    "\n",
    "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "  # Layer 14\n",
    "  x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_14')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 15\n",
    "  x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_15')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 16\n",
    "  x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_16')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 17\n",
    "  x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_17')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 18\n",
    "  x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_18')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 19\n",
    "  x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_19')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 20\n",
    "  x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_20')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  # Layer 21\n",
    "  skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "  skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "  skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "  skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "  x = concatenate([skip_connection, x])\n",
    "\n",
    "  # Layer 22\n",
    "  x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "  x = BatchNormalization(name='norm_22')(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "  if anc_box==True:\n",
    "    # Layer 23\n",
    "    x = Conv2D(BOX*(4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "    output = Reshape((GRID_H, GRID_W,BOX,4 + 1 + CLASS))(x)\n",
    "  else :\n",
    "    # Layer 23\n",
    "    x = Conv2D((4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "    output = Reshape((GRID_H, GRID_W,4 + 1 + CLASS))(x)\n",
    "\n",
    "  # small hack to allow true_boxes to be registered when Keras build the model \n",
    "  # for more information: https://github.com/fchollet/keras/issues/2790\n",
    "  #output = Lambda(lambda args: args[0])([output, true_boxes])#Change :Hasib\n",
    "\n",
    "  #model = Model([input_image, true_boxes], output)#Change :Hasib\n",
    "  model = Model(input_image, output)\n",
    "  return model\n",
    "  #model.load_weights('/content/drive/My Drive/Data/yolo_net_ep500_act.h5')\n",
    "\n",
    "\n",
    "class WeightReader:\n",
    "    def __init__(self, weight_file):\n",
    "        self.offset = 4\n",
    "        self.all_weights = np.fromfile(weight_file, dtype='float32')\n",
    "        \n",
    "    def read_bytes(self, size):\n",
    "        self.offset = self.offset + size\n",
    "        return self.all_weights[self.offset-size:self.offset]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.offset = 4\n",
    "\n",
    "def load_weights(model,path_wst):\n",
    "  wt_path = path_wts                      \n",
    "  weight_reader = WeightReader(wt_path)\n",
    "  weight_reader.reset()\n",
    "  nb_conv = 23\n",
    "\n",
    "  for i in range(1, nb_conv+1):\n",
    "      conv_layer = model.get_layer('conv_' + str(i))\n",
    "\n",
    "      if i < nb_conv:\n",
    "          norm_layer = model.get_layer('norm_' + str(i))\n",
    "\n",
    "          size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\n",
    "          beta  = weight_reader.read_bytes(size)\n",
    "          gamma = weight_reader.read_bytes(size)\n",
    "          mean  = weight_reader.read_bytes(size)\n",
    "          var   = weight_reader.read_bytes(size)\n",
    "\n",
    "          weights = norm_layer.set_weights([gamma, beta, mean, var])       \n",
    "\n",
    "      if len(conv_layer.get_weights()) > 1:\n",
    "          bias   = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "          kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "          kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "          kernel = kernel.transpose([2,3,1,0])\n",
    "          conv_layer.set_weights([kernel, bias])\n",
    "      else:\n",
    "          kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "          kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "          kernel = kernel.transpose([2,3,1,0])\n",
    "          conv_layer.set_weights([kernel])\n",
    "  return model\n",
    "\n",
    "\n",
    "def yolo_loss_0(y_true, y_pred):\n",
    "        loss=0\n",
    "      #for n in range(BATCH_SIZE):\n",
    "        for i in range(GRID_H):\n",
    "          for j in range(GRID_W):\n",
    "            for k in range(0,6):\n",
    "              temp=y_true[i,j,k]-y_pred[i,j,k]\n",
    "              #temp=temp**2\n",
    "              loss+=temp\n",
    "              \n",
    "        return loss \n",
    "def yolo_loss_1(y_true, y_pred):\n",
    "      loss=0\n",
    "          ### adjust w and h\n",
    "      ob_mask= tf.expand_dims(y_true[..., 4], axis=-1)\n",
    "      conf_mask=y_true[...,4]\n",
    "      \n",
    "      if anc_box==True:\n",
    "        cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
    "        cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "        cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\n",
    "\n",
    "        pred_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "        pred_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n",
    "      \n",
    "      else:\n",
    "        pred_xy=(y_pred[...,0:2])\n",
    "        pred_wh=(y_pred[...,2:4])\n",
    "      \n",
    "      true_xy=y_true[...,0:2]\n",
    "      true_wh=y_true[...,2:4]\n",
    "      \n",
    "      #pred_wh=tf.multiply(pred_wh,ob_mask)\n",
    "      pred_conf=y_pred[...,4]\n",
    "      ### adjust confidence\n",
    "      true_wh_half = true_wh / 2.\n",
    "      true_mins    = tf.subtract(true_xy,true_wh_half)\n",
    "      true_maxes   = tf.add(true_xy,true_wh_half)\n",
    "    \n",
    "      pred_wh_half = pred_wh / 2.\n",
    "      pred_mins    = tf.subtract(pred_xy,pred_wh_half)\n",
    "      pred_maxes   = tf.add(pred_xy,pred_wh_half)       \n",
    "    \n",
    "      intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "      intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "      intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "      intersect_areas = tf.multiply(intersect_wh[..., 0] , intersect_wh[..., 1])\n",
    "    \n",
    "      true_areas = tf.multiply(true_wh[..., 0] , true_wh[..., 1])\n",
    "      pred_areas = tf.multiply(pred_wh[..., 0] , pred_wh[..., 1])\n",
    "\n",
    "      union_areas =tf.subtract(tf.add(pred_areas,true_areas),intersect_areas)\n",
    "      intersect_areas=tf.add(intersect_areas,1)\n",
    "      union_areas=tf.add(union_areas,1)\n",
    "      iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "      \n",
    "      true_conf =tf.multiply( iou_scores,y_true[..., 4])\n",
    "      \n",
    "      loss_bb=tf.subtract(true_xy,pred_xy)\n",
    "      loss_bb=tf.square(loss_bb)\n",
    "      loss_bb=tf.multiply(loss_bb,ob_mask)\n",
    "      loss_bb=tf.reduce_sum(loss_bb)\n",
    "      loss_wh=tf.subtract((true_wh),(pred_wh))\n",
    "      loss_wh=tf.square(loss_wh)\n",
    "      loss_wh=tf.multiply(loss_wh,ob_mask)\n",
    "      loss_wh=tf.reduce_sum(loss_wh)\n",
    "      loss_conf=tf.subtract(true_conf,pred_conf)\n",
    "      loss_conf=tf.square(loss_conf)\n",
    "      loss_conf=tf.multiply(loss_conf,conf_mask)\n",
    "      loss_conf=tf.reduce_sum(loss_conf)\n",
    "      loss=loss_bb+loss_wh+loss_conf       \n",
    "      return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kNFzCsqgTlHT"
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "    \n",
    "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
    "    cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
    "\n",
    "    cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\n",
    "    \n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    conf_mask  = tf.zeros(mask_shape)\n",
    "    class_mask = tf.zeros(mask_shape)\n",
    "    \n",
    "    seen = tf.Variable(0.)\n",
    "    total_recall = tf.Variable(0.)\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust prediction\n",
    "    \"\"\"\n",
    "    ### adjust x and y      \n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
    "    \n",
    "    ### adjust w and h\n",
    "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1,1,1,BOX,2])\n",
    "    \n",
    "    ### adjust confidence\n",
    "    pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    pred_box_class = y_pred[..., 5:]\n",
    "    \n",
    "    \"\"\"\n",
    "    Adjust ground truth\n",
    "    \"\"\"\n",
    "    ### adjust x and y\n",
    "    true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
    "    \n",
    "    ### adjust w and h\n",
    "    true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
    "    \n",
    "    ### adjust confidence\n",
    "    true_wh_half = true_box_wh / 2.\n",
    "    true_mins    = true_box_xy - true_wh_half\n",
    "    true_maxes   = true_box_xy + true_wh_half\n",
    "    \n",
    "    pred_wh_half = pred_box_wh / 2.\n",
    "    pred_mins    = pred_box_xy - pred_wh_half\n",
    "    pred_maxes   = pred_box_xy + pred_wh_half       \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "    \n",
    "    true_box_conf = iou_scores * y_true[..., 4]\n",
    "    \n",
    "    ### adjust class probabilities\n",
    "    true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "    \n",
    "    \"\"\"\n",
    "    Determine the masks\n",
    "    \"\"\"\n",
    "    ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE\n",
    "    \n",
    "    ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
    "    # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "    '''\n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "    \n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins    = true_xy - true_wh_half\n",
    "    true_maxes   = true_xy + true_wh_half\n",
    "    \n",
    "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "    \n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins    = pred_xy - pred_wh_half\n",
    "    pred_maxes   = pred_xy + pred_wh_half    \n",
    "    \n",
    "    intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    best_ious = tf.reduce_max(iou_scores, axis=4) \n",
    "    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
    "    '''\n",
    "    # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\n",
    "    \n",
    "    ### class mask: simply the position of the ground truth boxes (the predictors)\n",
    "    class_mask = y_true[..., 4] * tf.gather(CLASS_WEIGHTS, true_box_class) * CLASS_SCALE       \n",
    "    '''\n",
    "    \"\"\"\n",
    "    Warm-up training\n",
    "    \"\"\"\n",
    "    no_boxes_mask = tf.to_float(coord_mask < COORD_SCALE/2.)\n",
    "    seen = tf.assign_add(seen, 1.)\n",
    "    \n",
    "    true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, WARM_UP_BATCHES), \n",
    "                          lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n",
    "                                   true_box_wh + tf.ones_like(true_box_wh) * np.reshape(ANCHORS, [1,1,1,BOX,2]) * no_boxes_mask, \n",
    "                                   tf.ones_like(coord_mask)],\n",
    "                          lambda: [true_box_xy, \n",
    "                                   true_box_wh,\n",
    "                                   coord_mask])\n",
    "    '''\n",
    "    \"\"\"\n",
    "    Finalize the loss\n",
    "    \"\"\"\n",
    "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
    "    nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
    "    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
    "    \n",
    "    loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
    "    \n",
    "    loss = loss_xy + loss_wh + loss_conf + loss_class\n",
    "        \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9qdIbN_a8at"
   },
   "source": [
    "### Data Ready Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hAALW0WuaCuO"
   },
   "outputs": [],
   "source": [
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "             return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3          \n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    box1_xmin,box1_ymin,box1_xmax,box1_ymax=box1\n",
    "    box2_xmin,box2_ymin,box2_xmax,box2_ymax=box2\n",
    "    intersect_w = _interval_overlap([box1_xmin, box1_xmax], [box2_xmin, box2_xmax])\n",
    "    intersect_h = _interval_overlap([box1_ymin, box1_ymax], [box2_ymin, box2_ymax])  \n",
    "    \n",
    "    intersect = intersect_w * intersect_h\n",
    "\n",
    "    w1, h1 = box1_xmax-box1_xmin, box1_ymax-box1_ymin\n",
    "    w2, h2 = box2_xmax-box2_xmin, box2_ymax-box2_ymin\n",
    "    \n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    \n",
    "    return float(intersect) / union\n",
    "  \n",
    "def Batch_Gen(train_imgs):\n",
    "        n=len(train_imgs)\n",
    "        x_batch = np.zeros((n,IMAGE_H, IMAGE_W,3),dtype=float)                         # input images\n",
    "        #b_batch = np.zeros((r_bound - l_bound, 1     , 1     , 1    ,  self.config['TRUE_BOX_BUFFER'], 4))   # list of self.config['TRUE_self.config['BOX']_BUFFER'] GT boxes\n",
    "        if anc_box==True:\n",
    "          y_batch = np.zeros((n, GRID_H, GRID_W,BOX,4+1+len(LABELS)),dtype=np.float)                # desired network output\n",
    "        else :\n",
    "          y_batch = np.zeros((n, GRID_H, GRID_W,4+1+len(LABELS)),dtype=np.float)                # desired network output\n",
    "        instance_count=0\n",
    "        for train_instance in train_imgs:\n",
    "            # augment input image and fix object's position and size\n",
    "            #img, all_objs = self.aug_image(train_instance, jitter=self.jitter)\n",
    "            image_name = train_instance['filename']\n",
    "            img = cv2.imread(image_name)\n",
    "            img = cv2.resize(img, (IMAGE_H,IMAGE_W))\n",
    "            img = img[:,:,::-1]\n",
    "            img_w=train_instance['height']\n",
    "            img_h=train_instance['width']\n",
    "            all_objs = train_instance['object']\n",
    "            # construct output from object's x, y, w, h\n",
    "            true_box_index = 0\n",
    "            anchors = [[0, 0, ANCHORS[2*i], ANCHORS[2*i+1]] for i in range(int(len(ANCHORS)//2))]\n",
    "            for obj in all_objs:\n",
    "                no_gridx=float(IMAGE_W / GRID_W)\n",
    "                no_gridy=float(IMAGE_H /GRID_H)\n",
    "                if obj['xmax'] > obj['xmin'] and obj['ymax'] > obj['ymin'] and obj['name'] in LABELS:\n",
    "                    center_x = .5*(obj['xmin'] + obj['xmax'])\n",
    "                    center_x = center_x/no_gridx\n",
    "                    center_y = .5*(obj['ymin'] + obj['ymax'])\n",
    "                    center_y=center_y/no_gridy\n",
    "                    grid_x = int(np.floor(center_x))\n",
    "                    grid_y = int(np.floor(center_y))\n",
    "                    #center_x-=grid_x\n",
    "                    #center_y-=grid_y\n",
    "                    if grid_x < GRID_W and grid_y < GRID_H:\n",
    "                        obj_indx  = LABELS.index(obj['name'])\n",
    "                        center_w = (obj['xmax'] - obj['xmin'])/no_gridx #/ (float(self.config['IMAGE_W'])# / self.config['GRID_W']) # unit: grid cell\n",
    "                        center_h = (obj['ymax'] - obj['ymin'])/no_gridy #/ (float(self.config['IMAGE_H'])# / self.config['GRID_H']) # unit: grid cell\n",
    "                        center_w=center_w\n",
    "                        center_h=center_h\n",
    "                        \n",
    "                        box = [center_x, center_y, center_w, center_h]\n",
    "\n",
    "                        # find the anchor that best predicts this box#Change :Hasib\n",
    "                        best_anchor = -1\n",
    "                        max_iou     = -1\n",
    "                        \n",
    "                        shifted_box = [0, 0, center_w, center_h]\n",
    "                        \n",
    "                        for i in range(len(anchors)):\n",
    "                            anchor = anchors[i]\n",
    "                            iou    = bbox_iou(shifted_box, anchor)\n",
    "                            \n",
    "                            if max_iou < iou:\n",
    "                                best_anchor = i\n",
    "                                max_iou     = iou\n",
    "                      \n",
    "                        # assign ground truth x, y, w, h, confidence and class probs to y_batch\n",
    "                        if anc_box==True:\n",
    "                          y_batch[instance_count, grid_y, grid_x, best_anchor,0:4] = box\n",
    "                          y_batch[instance_count, grid_y, grid_x, best_anchor,4  ] = 1.\n",
    "                          y_batch[instance_count, grid_y, grid_x, best_anchor,5+obj_indx] = 1\n",
    "                        else :\n",
    "                          y_batch[instance_count, grid_y, grid_x,0:4] = box\n",
    "                          y_batch[instance_count, grid_y, grid_x,4  ] = 1.\n",
    "                          y_batch[instance_count, grid_y, grid_x,5+obj_indx] = 1\n",
    "\n",
    "                        # assign the true box to b_batch\n",
    "                        #b_batch[instance_count, 0, 0, 0, true_box_index] = box#Change: Hasib\n",
    "                        \n",
    "                        #true_box_index += 1\n",
    "                        #true_box_index = true_box_index % self.config['TRUE_BOX_BUFFER']\n",
    "                            \n",
    "            # assign input image to x_batch\n",
    "            x_batch[instance_count] = img/255\n",
    "\n",
    "            # increase instance counter in current batch\n",
    "            instance_count += 1  \n",
    "\n",
    "        #print(' new batch created', idx)\n",
    "\n",
    "        return x_batch, y_batch\n",
    "\n",
    "import csv\n",
    "\n",
    "def read_data(dataset):\n",
    "  f=open(dataset+'/label.csv')\n",
    "  file=csv.reader(f,delimiter=',')\n",
    "  data=[]\n",
    "  i=0\n",
    "  sc=416.0\n",
    "  for line in file:\n",
    "      dt=line\n",
    "      H=dt[0]\n",
    "      W=dt[1]\n",
    "      xmin=(float(dt[2]))/sc\n",
    "      ymin=(float(dt[3]))/sc\n",
    "      xmax=(float(dt[4]))/sc\n",
    "      ymax=(float(dt[5]))/sc\n",
    "\n",
    "      output={\n",
    "          'filename':dataset+'/images/'+str(i)+'.jpg',\n",
    "          'height':H,\n",
    "          'width':W,\n",
    "          'object':[{'name':'None',\n",
    "          'xmin':xmin*IMAGE_W,\n",
    "          'ymin':ymin*IMAGE_H,\n",
    "          'xmax':xmax*IMAGE_W,\n",
    "          'ymax':ymax*IMAGE_H}]\n",
    "          }\n",
    "\n",
    "      data.append(output)\n",
    "      i=i+1\n",
    "  return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-sSJbnsw8Vu"
   },
   "outputs": [],
   "source": [
    "\n",
    "if colab_run==True :data_dir='/content/drive/My Drive/CNN_Basic/'\n",
    "else: data_dir=''\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "def read_content(xml_file: str):\n",
    "    objs=[]\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    list_with_all_boxes = []\n",
    "    filename = root.find('filename').text\n",
    "    size=root.find('size')\n",
    "    img_h=int(size.find('height').text)\n",
    "    img_w=int(size.find('width').text)\n",
    "    print(img_h)\n",
    "    for boxes in root.iter('object'):\n",
    "        \n",
    "        name = boxes.find('name').text\n",
    "        ymin, xmin, ymax, xmax = None, None, None, None\n",
    "        \n",
    "        for box in boxes.findall(\"bndbox\"):\n",
    "            ymin = int(box.find(\"ymin\").text)\n",
    "            xmin = int(box.find(\"xmin\").text)\n",
    "            ymax = int(box.find(\"ymax\").text)\n",
    "            xmax = int(box.find(\"xmax\").text)\n",
    "        wf=IMAGE_W/img_w\n",
    "        hf=IMAGE_H/img_h\n",
    "        obj={'name':name,\n",
    "          'xmin':xmin*wf,\n",
    "          'ymin':ymin*hf,\n",
    "          'xmax':xmax*wf,\n",
    "          'ymax':ymax*hf}\n",
    "        objs.append(obj)\n",
    "        \n",
    "    out={\n",
    "          'filename':data_dir+'VOC_Images/'+filename,\n",
    "          'height':img_h,\n",
    "          'width':img_w,\n",
    "          'object':objs\n",
    "    }\n",
    "        \n",
    "    return filename, list_with_all_boxes,out\n",
    "  \n",
    "import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "save=False\n",
    "if save==True:\n",
    "  fnames=[]\n",
    "  all_data=[]\n",
    "  i=0\n",
    "  \n",
    "  for file in glob.glob(data_dir+'Annotations/*'):\n",
    "    i+=1\n",
    "    print(i)\n",
    "    _,_,obj=read_content(file)\n",
    "    #print(data)\n",
    "    #break\n",
    "    #fname, boxes, objs = read_content(file)\n",
    "    #fnames.append(fname)\n",
    "    all_data.append(obj)\n",
    " \n",
    "  #df=pd.DataFrame([fnames,obj_list],index=['fname','objs']).transpose()\n",
    "  #df=df.sample(frac=1,random_state=10).reset_index(drop=True)\n",
    "  #n=len(df)\n",
    "  #split=int(0.8*n)\n",
    "  #train_data=df.loc[:split]\n",
    "  #val_data=df.loc[split:].reset_index(drop=True)\n",
    "  import pickle\n",
    "  f=open(data_dir+'_VOC_dfs','wb')\n",
    "  pickle.dump(all_data,f)\n",
    "  f.close()\n",
    "import pickle\n",
    "f=open(data_dir+'_VOC_dfs','rb')\n",
    "all_data=pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LSzzHNCSbIPy"
   },
   "source": [
    "### Train Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xz2kN4COaIVh"
   },
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "  optimizer = Adam(lr=0.5e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\t#optimizer = SGD(lr=1e-4, decay=0.0005, momentum=0.9)\n",
    "\t#optimizer = RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "  model.compile(loss=yolo_loss_1, optimizer=optimizer,metrics=['accuracy'])\n",
    "  if anc_box==True:\n",
    "    model.compile(loss=custom_loss, optimizer=optimizer,metrics=['accuracy'])\n",
    "  history=model.fit(x_train, y_train,batch_size=batch_size,epochs=50,validation_data=(x_test,y_test),shuffle=True)\n",
    "\t#history=model.fit_generator(generator= train_batch, \n",
    "\t\t\t\t\t\t#steps_per_epoch  = len(train_batch), \n",
    "\t\t\t\t\t\t#epochs           = 60, \n",
    "\t\t\t\t\t\t#verbose          = 1,\n",
    "\t\t\t\t\t\t#validation_data  = valid_batch,\n",
    "\t\t\t\t\t\t#validation_steps = len(valid_batch),\n",
    "\t\t\t\t\t\t#callbacks        = [early_stop], \n",
    "\t\t\t\t\t\t#max_queue_size   = 3)\n",
    "  plt.plot(history.history['acc'])\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.title('model accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'test'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  # summarize history for loss\n",
    "  plt.plot(history.history['loss'])\n",
    "  plt.plot(history.history['val_loss'])\n",
    "  plt.title('model loss')\n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['train', 'test'], loc='upper left')\n",
    "  plt.show()\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14023,
     "status": "ok",
     "timestamp": 1562823140352,
     "user": {
      "displayName": "irfan hasib",
      "photoUrl": "https://lh4.googleusercontent.com/-6rVnRThUoWk/AAAAAAAAAAI/AAAAAAAADsk/X6dBOaUVMS4/s64/photo.jpg",
      "userId": "16061096143782894681"
     },
     "user_tz": -360
    },
    "id": "Md5yqGs0ZURg",
    "outputId": "18fb074f-7747-4ce8-8e49-f97736631dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 416, 416, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 416, 416, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)     (None, 416, 416, 32) 128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 416, 416, 32) 0           norm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 208, 208, 32) 0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 208, 208, 64) 18432       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)     (None, 208, 208, 64) 256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 208, 208, 64) 0           norm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 104, 104, 64) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 104, 104, 128 73728       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_3 (BatchNormalization)     (None, 104, 104, 128 512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 104, 104, 128 0           norm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 104, 104, 64) 8192        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_4 (BatchNormalization)     (None, 104, 104, 64) 256         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 104, 104, 64) 0           norm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 104, 104, 128 73728       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_5 (BatchNormalization)     (None, 104, 104, 128 512         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 104, 104, 128 0           norm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 52, 52, 128)  0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 52, 52, 256)  294912      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_6 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 52, 52, 256)  0           norm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 52, 52, 128)  32768       leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_7 (BatchNormalization)     (None, 52, 52, 128)  512         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 52, 52, 128)  0           norm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 52, 52, 256)  294912      leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_8 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 52, 52, 256)  0           norm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 26, 26, 256)  0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 26, 26, 512)  1179648     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_9 (BatchNormalization)     (None, 26, 26, 512)  2048        conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 26, 26, 512)  0           norm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_10 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 26, 26, 256)  0           norm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_11 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 26, 26, 512)  0           norm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_12 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 26, 26, 256)  0           norm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_13 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 26, 26, 512)  0           norm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 13, 13, 512)  0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 13, 13, 1024) 4718592     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_14 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_15 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 13, 13, 512)  0           norm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_16 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_17 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 13, 13, 512)  0           norm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_18 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_19 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "norm_19 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_21 (Conv2D)                (None, 26, 26, 64)   32768       leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_21 (BatchNormalization)    (None, 26, 26, 64)   256         conv_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 26, 26, 64)   0           norm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_20 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 13, 13, 256)  0           leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 13, 13, 1280) 0           lambda[0][0]                     \n",
      "                                                                 leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_22 (Conv2D)                (None, 13, 13, 1024) 11796480    concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "norm_22 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 13, 13, 1024) 0           norm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_23 (Conv2D)                (None, 13, 13, 25)   25625       leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 13, 13, 25)   0           conv_23[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 50,573,561\n",
      "Trainable params: 50,552,889\n",
      "Non-trainable params: 20,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#root='/content/drive/My Drive/Data/'\n",
    "root=''\n",
    "path_wts=root+'yolo.weights'\n",
    "path_wts_final=root+'yolo_minimal_anc_500.h5'\n",
    "#path_data=root+'np_500'\n",
    "#path_pred=root+'/np_500/images/'\n",
    "  \n",
    "if train==True:\n",
    "  #data=read_data(path_data)\n",
    "  \n",
    "  train_imgs=all_data[:400]\n",
    "  valid_imgs=all_data[400:460]\n",
    "  \n",
    "  x_train,y_train = Batch_Gen(train_imgs)\n",
    "  x_test,y_test = Batch_Gen(valid_imgs)\n",
    "model=build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VOC_Images/000005.jpg'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs[0]['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 742998,
     "status": "ok",
     "timestamp": 1562823869375,
     "user": {
      "displayName": "irfan hasib",
      "photoUrl": "https://lh4.googleusercontent.com/-6rVnRThUoWk/AAAAAAAAAAI/AAAAAAAADsk/X6dBOaUVMS4/s64/photo.jpg",
      "userId": "16061096143782894681"
     },
     "user_tz": -360
    },
    "id": "DKBYfi42VnXe",
    "outputId": "afb1c882-3192-4bb0-db43-c68c9b9e2843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400 samples, validate on 60 samples\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 24s 59ms/step - loss: 2202.6670 - acc: 0.4641 - val_loss: 973.0718 - val_acc: 0.2048\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 327.8623 - acc: 0.3995 - val_loss: 517.5825 - val_acc: 0.3386\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 160.0794 - acc: 0.3969 - val_loss: 399.4484 - val_acc: 0.3922\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 99.8679 - acc: 0.3893 - val_loss: 344.0642 - val_acc: 0.3974\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 75.5121 - acc: 0.3940 - val_loss: 320.5910 - val_acc: 0.4149\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 59.1415 - acc: 0.3893 - val_loss: 295.3079 - val_acc: 0.4186\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 42.2217 - acc: 0.3853 - val_loss: 270.6818 - val_acc: 0.4142\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 38.5409 - acc: 0.3825 - val_loss: 264.0198 - val_acc: 0.4190\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 34.7468 - acc: 0.3876 - val_loss: 246.5884 - val_acc: 0.4058\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 32.8557 - acc: 0.3863 - val_loss: 246.0338 - val_acc: 0.4134\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 28.8270 - acc: 0.3815 - val_loss: 239.1355 - val_acc: 0.4075\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 27.1791 - acc: 0.3884 - val_loss: 232.2081 - val_acc: 0.4106\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 16s 40ms/step - loss: 26.4863 - acc: 0.3824 - val_loss: 227.0233 - val_acc: 0.3906\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 20.3290 - acc: 0.3843 - val_loss: 219.8248 - val_acc: 0.3917\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 18.7611 - acc: 0.3821 - val_loss: 222.4872 - val_acc: 0.3947\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 17.1529 - acc: 0.3810 - val_loss: 208.9329 - val_acc: 0.3931\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 15.4052 - acc: 0.3797 - val_loss: 209.4494 - val_acc: 0.3882\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 16.0623 - acc: 0.3795 - val_loss: 209.0985 - val_acc: 0.3975\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 15.3798 - acc: 0.3739 - val_loss: 209.9738 - val_acc: 0.4044\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 17.2705 - acc: 0.3786 - val_loss: 211.5918 - val_acc: 0.4031\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 16.3171 - acc: 0.3764 - val_loss: 215.3422 - val_acc: 0.3875\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 13.9665 - acc: 0.3789 - val_loss: 203.5722 - val_acc: 0.3955\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 12.5500 - acc: 0.3836 - val_loss: 196.7039 - val_acc: 0.3984\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 12.2911 - acc: 0.3771 - val_loss: 207.8009 - val_acc: 0.3963\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 11.3504 - acc: 0.3756 - val_loss: 197.0875 - val_acc: 0.3924\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 11.9800 - acc: 0.3760 - val_loss: 199.7585 - val_acc: 0.4012\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 11.8316 - acc: 0.3816 - val_loss: 201.0792 - val_acc: 0.4011\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 10.5207 - acc: 0.3783 - val_loss: 197.3656 - val_acc: 0.3938\n",
      "Epoch 29/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 9.9432 - acc: 0.3774 - val_loss: 195.0887 - val_acc: 0.3924\n",
      "Epoch 30/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 9.3097 - acc: 0.3802 - val_loss: 185.6370 - val_acc: 0.3935\n",
      "Epoch 31/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 9.1272 - acc: 0.3808 - val_loss: 195.5054 - val_acc: 0.3958\n",
      "Epoch 32/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 8.7999 - acc: 0.3797 - val_loss: 191.1886 - val_acc: 0.3984\n",
      "Epoch 33/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 8.8073 - acc: 0.3807 - val_loss: 197.6057 - val_acc: 0.3960\n",
      "Epoch 34/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 8.0622 - acc: 0.3799 - val_loss: 188.8331 - val_acc: 0.3927\n",
      "Epoch 35/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 7.3314 - acc: 0.3834 - val_loss: 186.8406 - val_acc: 0.3989\n",
      "Epoch 36/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 7.1867 - acc: 0.3819 - val_loss: 189.2710 - val_acc: 0.4028\n",
      "Epoch 37/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 8.8814 - acc: 0.3797 - val_loss: 190.5811 - val_acc: 0.3870\n",
      "Epoch 38/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 9.8760 - acc: 0.3765 - val_loss: 192.0418 - val_acc: 0.3888\n",
      "Epoch 39/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 8.5067 - acc: 0.3796 - val_loss: 178.9342 - val_acc: 0.3987\n",
      "Epoch 40/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 7.6790 - acc: 0.3771 - val_loss: 178.6440 - val_acc: 0.3952\n",
      "Epoch 41/50\n",
      "400/400 [==============================] - 16s 39ms/step - loss: 8.9840 - acc: 0.3747 - val_loss: 180.3377 - val_acc: 0.4012\n",
      "Epoch 42/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 10.1199 - acc: 0.3772 - val_loss: 185.9419 - val_acc: 0.3949\n",
      "Epoch 43/50\n",
      "400/400 [==============================] - 15s 39ms/step - loss: 10.1649 - acc: 0.3761 - val_loss: 174.8741 - val_acc: 0.3908\n",
      "Epoch 44/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 9.2674 - acc: 0.3754 - val_loss: 183.7692 - val_acc: 0.3899\n",
      "Epoch 45/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 8.8009 - acc: 0.3805 - val_loss: 177.4237 - val_acc: 0.3870\n",
      "Epoch 46/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 9.6638 - acc: 0.3771 - val_loss: 184.4803 - val_acc: 0.3848\n",
      "Epoch 47/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 8.9449 - acc: 0.3789 - val_loss: 179.5776 - val_acc: 0.3907\n",
      "Epoch 48/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 9.0634 - acc: 0.3792 - val_loss: 168.9178 - val_acc: 0.4079\n",
      "Epoch 49/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 7.8196 - acc: 0.3819 - val_loss: 173.5638 - val_acc: 0.3963\n",
      "Epoch 50/50\n",
      "400/400 [==============================] - 15s 38ms/step - loss: 7.7658 - acc: 0.3799 - val_loss: 174.1646 - val_acc: 0.3869\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if train==True:\n",
    "\tmodel=load_weights(model,path_wts)\n",
    "\tmodel=train_model(model)\n",
    "if train==False:\n",
    "\tmodel.load_weights(path_wts_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6KMduvZAbNMY"
   },
   "source": [
    "### Predicion Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "15upCTbggjjjGTtdZ00odt0VSTbBrTO0i"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16930,
     "status": "error",
     "timestamp": 1562824592673,
     "user": {
      "displayName": "irfan hasib",
      "photoUrl": "https://lh4.googleusercontent.com/-6rVnRThUoWk/AAAAAAAAAAI/AAAAAAAADsk/X6dBOaUVMS4/s64/photo.jpg",
      "userId": "16061096143782894681"
     },
     "user_tz": -360
    },
    "id": "S6ZO-9qLaNBN",
    "outputId": "70174882-7588-41e9-c56e-b6a95918e7b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _softmax(x, axis=-1, t=-100.):\n",
    "    x = x - np.max(x)\n",
    "    \n",
    "    if np.min(x) < t:\n",
    "        x = x/np.min(x)*t\n",
    "        \n",
    "    e_x = np.exp(x)\n",
    "    \n",
    "    return e_x / e_x.sum(axis, keepdims=True)\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def decode_netout_anc(netout, anchors, nb_class, obj_threshold=0.3, nms_threshold=0.3):\n",
    "    #grid_h, grid_w, nb_box = netout.shape[:3]\n",
    "    grid_h, grid_w = netout.shape[:2]\n",
    "\n",
    "    boxes = []\n",
    "    \n",
    "    # decode the output by the network\n",
    "    netout[..., 4]  = _sigmoid(netout[..., 4])\n",
    "    netout[..., 5:] = netout[..., 4][..., np.newaxis] * _softmax(netout[..., 5:])\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_threshold\n",
    "    \n",
    "    for row in range(grid_h):\n",
    "        for col in range(grid_w):\n",
    "            for b in range(BOX):\n",
    "                # from 4th element onwards are confidence and class classes\n",
    "                classes = netout[row,col,b,5:]\n",
    "                #classes = netout[row,col,5:]\n",
    "                confidence = netout[row,col,b,4]\n",
    "                if np.sum(classes) > 0:\n",
    "                    # first 4 elements are x, y, w, and h\n",
    "                    #x, y, w, h = netout[row,col,b,:4]\n",
    "                    x, y, w, h = netout[row,col,b,:4]\n",
    "                    #print(col,_sigmoid(x-col),row,_sigmoid(y),w,h)\n",
    "                    x = (col + _sigmoid(x)) / grid_w # center position, unit: image width\n",
    "                    y = (row + _sigmoid(y)) / grid_h # center position, unit: image height\n",
    "                    w = ANCHORS[2 * b + 0] * np.exp(w) / grid_w # unit: image width\n",
    "                    h = ANCHORS[2 * b + 1] * np.exp(h) / grid_h # unit: image height\n",
    "                    #print(x,y,w,h)\n",
    "                    classes=np.argmax(classes)\n",
    "                    \n",
    "                    box = (x-w/2, y-h/2, x+w/2, y+h/2, confidence, classes)\n",
    "                    box = (x-w/2, y-h/2, x+w/2, y+h/2, confidence, classes)\n",
    "                    if abs(box[0])<=1 and abs(box[1])<=1 and box[2]<=1 and box[3]<=1 :\n",
    "                      if (box[0])>=0 and (box[1])>=0 and box[2]>=0 and box[3]>=0 :\n",
    "                        boxes.append(box)\n",
    "                    \n",
    "\n",
    "                        \n",
    "    indx=np.argsort([box[4] for box in boxes])\n",
    "    f_boxes=[]\n",
    "    #indx=reversed(indx)\n",
    "    if len(indx)>=3:\n",
    "      for i in range(1,2):\n",
    "        ind=indx[-1*i]\n",
    "        f_boxes.append(boxes[ind])\n",
    "    else:\n",
    "      f_boxes=boxes\n",
    "    return f_boxes    \n",
    "    \n",
    "def decode_netout_1(netout, anchors, nb_class, obj_threshold=0.3, nms_threshold=0.3):\n",
    "    #grid_h, grid_w, nb_box = netout.shape[:3]\n",
    "    grid_h, grid_w = netout.shape[:2]\n",
    "\n",
    "    boxes = []\n",
    "    \n",
    "    # decode the output by the network\n",
    "    netout[..., 4]  = _sigmoid(netout[..., 4])\n",
    "    netout[..., 5:] = netout[..., 4][..., np.newaxis] * _softmax(netout[..., 5:])\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_threshold\n",
    "    print('A')\n",
    "    for row in range(grid_h):\n",
    "        for col in range(grid_w):\n",
    "            #for b in range(BOX):\n",
    "                # from 4th element onwards are confidence and class classes\n",
    "                classes = netout[row,col,5:]\n",
    "                #classes = netout[row,col,5:]\n",
    "                confidence = netout[row,col,4]\n",
    "                if np.sum(classes) > 0:\n",
    "                    # first 4 elements are x, y, w, and h\n",
    "                    #x, y, w, h = netout[row,col,b,:4]\n",
    "                    x, y, w, h = netout[row,col,:4]\n",
    "                    #print(col,_sigmoid(x-col),row,_sigmoid(y),w,h)\n",
    "                    x = x*(32/416) # center position, unit: image width\n",
    "                    y = y*(32/416) # center position, unit: image height\n",
    "                    w = w*(32/416) # unit: image width\n",
    "                    h = h*(32/416) # unit: image height\n",
    "                    #print(x,y,w,h)\n",
    "                    classes=np.argmax(classes)\n",
    "                    \n",
    "                    box = (x-w/2, y-h/2, x+w/2, y+h/2, confidence, classes)\n",
    "                    if abs(box[0])<=1 and abs(box[1])<=1 and box[2]<=1 and box[3]<=1 :\n",
    "                      if (box[0])>=0 and (box[1])>=0 and box[2]>=0 and box[3]>=0 :\n",
    "                        boxes.append(box)\n",
    "                    \n",
    "                      \n",
    "    \n",
    "    indx=np.argsort([box[4] for box in boxes])\n",
    "    # remove the boxes which are less likely than a obj_threshold\n",
    "    #obj_threshold=0\n",
    "    #print(boxes)\n",
    "    #for box in boxes:\n",
    "    #  if box[4]>obj_threshold:\n",
    "    #      obj_threshold=box[4]\n",
    "    #boxes = [box for box in boxes if box[4] >= obj_threshold-0.1]\n",
    "    \n",
    "    f_boxes=[]\n",
    "    #indx=reversed(indx)\n",
    "    if len(indx)>=3:\n",
    "      for i in range(1,2):\n",
    "        ind=indx[-1*i]\n",
    "        f_boxes.append(boxes[ind])\n",
    "    else:\n",
    "      f_boxes=boxes\n",
    "    print('B')\n",
    "    return f_boxes    \n",
    "\n",
    "def draw_boxes_1(image, boxes, labels,t_lbl=None):\n",
    "    image_h, image_w, _ = image.shape\n",
    "\n",
    "    for box in boxes:\n",
    "        xmin = int(box[0]*image_w)\n",
    "        ymin = int(box[1]*image_h)\n",
    "        xmax = int(box[2]*image_w)\n",
    "        ymax = int(box[3]*image_h)\n",
    "        x_off=20\n",
    "        y_off=20\n",
    "        print(xmin,ymin,xmax,ymax)\n",
    "        print(box)\n",
    "        cv2.rectangle(image, (xmin-x_off,ymin-y_off), (xmax+x_off,ymax+y_off), (255,0,0), 3)\n",
    "        cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (0,255,0), 3)\n",
    "        if t_lbl !=None:\n",
    "          cv2.rectangle(image, (t_lbl[0],t_lbl[1]), (t_lbl[2],t_lbl[3]), (0,0,255), 3)\n",
    "        cv2.putText(image, \n",
    "                    labels[box[5]] + ' ' + str(box[4]), \n",
    "                    (xmin, ymin - 13), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    1e-3 * image_h, \n",
    "                    (0,255,0), 1)\n",
    "        \n",
    "    return image\n",
    "\n",
    "\"\"\"# Perform detection on image\"\"\"\n",
    "error=0\n",
    "count=0\n",
    "import pandas as pd\n",
    "lbls=pd.read_csv(path_data+'/label.csv',names=[0,1,2,3,4,5])\n",
    "  \n",
    "for i in range(400,450):\n",
    "  count+=1\n",
    "  image = cv2.imread(path_pred+str(i)+'.jpg')\n",
    "  H_off=int(image.shape[0]*0.1)\n",
    "  W_off=int(image.shape[1]*0.1)\n",
    "  #image=image[H_off:-1*H_off,W_off:-1*W_off,:]\n",
    "  dummy_array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))\n",
    "\n",
    "  \n",
    "\n",
    "  input_image = cv2.resize(image, (416, 416))\n",
    "  input_image = input_image / 255.\n",
    "  input_image = input_image[:,:,::-1]\n",
    "  input_image = np.expand_dims(input_image, 0)\n",
    "\n",
    "  netout = model.predict(input_image)\n",
    "  #print(netout[0,:,:,0:2])\n",
    "\n",
    "\n",
    "  if anc_box==True:\n",
    "    boxes = decode_netout_anc(netout[0], \n",
    "                        obj_threshold=.60,\n",
    "                        nms_threshold=.90,\n",
    "                        anchors=ANCHORS, \n",
    "                        nb_class=CLASS)\n",
    "  else:\n",
    "    boxes = decode_netout_1(netout[0], \n",
    "                        obj_threshold=0.60,\n",
    "                        nms_threshold=.90,\n",
    "                        anchors=ANCHORS, \n",
    "                        nb_class=CLASS)\n",
    "  \n",
    "  true_lb=list(lbls.loc[i,2:5])\n",
    "  err=np.sum(np.square(np.array(true_lb)-np.array(boxes[0][:4])*416))\n",
    "  if err<100:\n",
    "    error+=err\n",
    "  else:\n",
    "    error+=100\n",
    "  #boxex.appned(true_lb)\n",
    "  image = draw_boxes_1(image, boxes, LABELS,true_lb)\n",
    "  plt.figure(figsize=(10,10))\n",
    "  plt.imshow(image[:,:,::-1]); plt.show()\n",
    "  print(err)\n",
    "print('mean error',error/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aJ8mkUunpBaK"
   },
   "outputs": [],
   "source": [
    "model.save('yolo_400.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v55OMypTzvzQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lbls=pd.read_csv(path_data+'/label.csv',names=[0,1,2,3,4,5])\n",
    "true_lb=list(lbls.loc[0,0:5])\n",
    "true_lb"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Minimal_yolo_v_3_functioned",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
